{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "lab4_text_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hExKCzh6doIW"
      },
      "source": [
        "# Lab 4 - Neural Network Classifier Using Simple Word Embeddings\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HixoFOoCIJ7V"
      },
      "source": [
        "In this session, we demonstrate how to solve a text classification task using simple \n",
        "feedforward neural network classifier. We will use IMDB Large Movie Review Dataset to train a binary classification model, able to predict whether a review is positive or negative. First, our network takes one-hot word vectors as input, averages them to make one vector and trains a \n",
        "fully-connected layer to predict the output. In the second part, we replace the one-hot vectors with the word embeddings and add a layer to see how much that improves the performance.\n",
        "\n",
        "We are going to use Keras Sequential API in this session. The Sequential API allows you to make models layer-by-layer. But it is not straightforward to define models where layers connect to more than just the previous and next layers. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m8fpBfhBpupy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c3f31534-ac7f-4967-88c9-38befda1271c"
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "from keras.layers import Lambda, GlobalAveragePooling1D, Dense, Embedding\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cqvPQvgvPv1W"
      },
      "source": [
        "### Downloading data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EundMtGPpCdf"
      },
      "source": [
        "The dataset we will be using is the IMDB Large Movie Review Dataset, which consists of 50000 labeled movie reviews. These are split into 25,000 reviews for training and 25,000 reviews for testing. The  dataset contains an even number of positive and negative reviews, so randomly guessing yields 50% accuracy. The data is preprocessed. For text classification, it is ususal to limit the size of the vocabulary to stop the dataset from becoming too sparse, creating possible overfitting. We keep the top 10,000 most frequently occurring words in the training data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NyuSzkafqNca",
        "colab": {}
      },
      "source": [
        "imdb = keras.datasets.imdb\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6U4iCV9-rmay"
      },
      "source": [
        "We now can start playing around with the data, letâ€™s first see the length:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h-gjWRAuqg5s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "c652dc38-d1e3-4de1-d105-ab1713207f3b"
      },
      "source": [
        "print(\"Training entries: {}, labels: {}\".format(len(X_train), len(y_train)))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training entries: 25000, labels: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MTRZrpcyr-4x"
      },
      "source": [
        "The  reviews have been converted to integers and each integer represents a  word in a dictionary. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "79Ev72Kgq4XL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4b3583a7-c7e0-49b7-95df-41658d676600"
      },
      "source": [
        " X_train[0]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 14,\n",
              " 22,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 973,\n",
              " 1622,\n",
              " 1385,\n",
              " 65,\n",
              " 458,\n",
              " 4468,\n",
              " 66,\n",
              " 3941,\n",
              " 4,\n",
              " 173,\n",
              " 36,\n",
              " 256,\n",
              " 5,\n",
              " 25,\n",
              " 100,\n",
              " 43,\n",
              " 838,\n",
              " 112,\n",
              " 50,\n",
              " 670,\n",
              " 2,\n",
              " 9,\n",
              " 35,\n",
              " 480,\n",
              " 284,\n",
              " 5,\n",
              " 150,\n",
              " 4,\n",
              " 172,\n",
              " 112,\n",
              " 167,\n",
              " 2,\n",
              " 336,\n",
              " 385,\n",
              " 39,\n",
              " 4,\n",
              " 172,\n",
              " 4536,\n",
              " 1111,\n",
              " 17,\n",
              " 546,\n",
              " 38,\n",
              " 13,\n",
              " 447,\n",
              " 4,\n",
              " 192,\n",
              " 50,\n",
              " 16,\n",
              " 6,\n",
              " 147,\n",
              " 2025,\n",
              " 19,\n",
              " 14,\n",
              " 22,\n",
              " 4,\n",
              " 1920,\n",
              " 4613,\n",
              " 469,\n",
              " 4,\n",
              " 22,\n",
              " 71,\n",
              " 87,\n",
              " 12,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 38,\n",
              " 76,\n",
              " 15,\n",
              " 13,\n",
              " 1247,\n",
              " 4,\n",
              " 22,\n",
              " 17,\n",
              " 515,\n",
              " 17,\n",
              " 12,\n",
              " 16,\n",
              " 626,\n",
              " 18,\n",
              " 2,\n",
              " 5,\n",
              " 62,\n",
              " 386,\n",
              " 12,\n",
              " 8,\n",
              " 316,\n",
              " 8,\n",
              " 106,\n",
              " 5,\n",
              " 4,\n",
              " 2223,\n",
              " 5244,\n",
              " 16,\n",
              " 480,\n",
              " 66,\n",
              " 3785,\n",
              " 33,\n",
              " 4,\n",
              " 130,\n",
              " 12,\n",
              " 16,\n",
              " 38,\n",
              " 619,\n",
              " 5,\n",
              " 25,\n",
              " 124,\n",
              " 51,\n",
              " 36,\n",
              " 135,\n",
              " 48,\n",
              " 25,\n",
              " 1415,\n",
              " 33,\n",
              " 6,\n",
              " 22,\n",
              " 12,\n",
              " 215,\n",
              " 28,\n",
              " 77,\n",
              " 52,\n",
              " 5,\n",
              " 14,\n",
              " 407,\n",
              " 16,\n",
              " 82,\n",
              " 2,\n",
              " 8,\n",
              " 4,\n",
              " 107,\n",
              " 117,\n",
              " 5952,\n",
              " 15,\n",
              " 256,\n",
              " 4,\n",
              " 2,\n",
              " 7,\n",
              " 3766,\n",
              " 5,\n",
              " 723,\n",
              " 36,\n",
              " 71,\n",
              " 43,\n",
              " 530,\n",
              " 476,\n",
              " 26,\n",
              " 400,\n",
              " 317,\n",
              " 46,\n",
              " 7,\n",
              " 4,\n",
              " 2,\n",
              " 1029,\n",
              " 13,\n",
              " 104,\n",
              " 88,\n",
              " 4,\n",
              " 381,\n",
              " 15,\n",
              " 297,\n",
              " 98,\n",
              " 32,\n",
              " 2071,\n",
              " 56,\n",
              " 26,\n",
              " 141,\n",
              " 6,\n",
              " 194,\n",
              " 7486,\n",
              " 18,\n",
              " 4,\n",
              " 226,\n",
              " 22,\n",
              " 21,\n",
              " 134,\n",
              " 476,\n",
              " 26,\n",
              " 480,\n",
              " 5,\n",
              " 144,\n",
              " 30,\n",
              " 5535,\n",
              " 18,\n",
              " 51,\n",
              " 36,\n",
              " 28,\n",
              " 224,\n",
              " 92,\n",
              " 25,\n",
              " 104,\n",
              " 4,\n",
              " 226,\n",
              " 65,\n",
              " 16,\n",
              " 38,\n",
              " 1334,\n",
              " 88,\n",
              " 12,\n",
              " 16,\n",
              " 283,\n",
              " 5,\n",
              " 16,\n",
              " 4472,\n",
              " 113,\n",
              " 103,\n",
              " 32,\n",
              " 15,\n",
              " 16,\n",
              " 5345,\n",
              " 19,\n",
              " 178,\n",
              " 32]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Tvuu4KhStqei"
      },
      "source": [
        "We can convert integers back to words by querying a dictionary object that contains the integer to string mapping:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gMCH1OoDrSNR",
        "colab": {}
      },
      "source": [
        "\n",
        "word_index = imdb.get_word_index()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5IreFXgruZot"
      },
      "source": [
        "Index 1 represents the beginning of the sentence and the index 2 is assigned to all unknown tokens. Index 0 will be used for padding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "abIb7Fe5u3GQ",
        "colab": {}
      },
      "source": [
        "\n",
        "word_index = {k:(v+3) for k,v in word_index.items()}\n",
        "word_index[\"<PAD>\"] = 0\n",
        "word_index[\"<START>\"] = 1\n",
        "word_index[\"<UNK>\"] = 2  \n",
        "word_index[\"<UNUSED>\"] = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9TnnSuspvC5b"
      },
      "source": [
        "To reverse key and values in a dictionary:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nKOiVVXQu-_I",
        "colab": {}
      },
      "source": [
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZmTJEm8xvUvW"
      },
      "source": [
        "To view a word:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SqN5jgVKvJJZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "a9da5b6a-fd7f-4e9f-8f55-0e99dadd6886"
      },
      "source": [
        "reverse_word_index[25]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'you'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Q6QjrzgVvrYn"
      },
      "source": [
        "And to recreate the whole sentence from our training data we define decode_review:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wvrKeMgxvWlv",
        "colab": {}
      },
      "source": [
        "def decode_review(text):\n",
        "    return ' '.join([reverse_word_index.get(i, '?') for i in text])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Sxg4YA_NvdRg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "outputId": "1fc8b401-16d4-4a69-99ab-0b7326737f96"
      },
      "source": [
        "decode_review(X_train[10])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"<START> french horror cinema has seen something of a revival over the last couple of years with great films such as inside and <UNK> romance <UNK> on to the scene <UNK> <UNK> the revival just slightly but stands head and shoulders over most modern horror titles and is surely one of the best french horror films ever made <UNK> was obviously shot on a low budget but this is made up for in far more ways than one by the originality of the film and this in turn is <UNK> by the excellent writing and acting that ensure the film is a winner the plot focuses on two main ideas prison and black magic the central character is a man named <UNK> sent to prison for fraud he is put in a cell with three others the quietly insane <UNK> body building <UNK> marcus and his retarded boyfriend daisy after a short while in the cell together they stumble upon a hiding place in the wall that contains an old <UNK> after <UNK> part of it they soon realise its magical powers and realise they may be able to use it to break through the prison walls br br black magic is a very interesting topic and i'm actually quite surprised that there aren't more films based on it as there's so much scope for things to do with it it's fair to say that <UNK> makes the best of it's <UNK> as despite it's <UNK> the film never actually feels restrained and manages to flow well throughout director eric <UNK> provides a great atmosphere for the film the fact that most of it takes place inside the central prison cell <UNK> that the film feels very claustrophobic and this immensely benefits the central idea of the prisoners wanting to use magic to break out of the cell it's very easy to get behind them it's often said that the unknown is the thing that really <UNK> people and this film proves that as the director <UNK> that we can never really be sure of exactly what is round the corner and this helps to ensure that <UNK> actually does manage to be quite frightening the film is memorable for a lot of reasons outside the central plot the characters are all very interesting in their own way and the fact that the book itself almost takes on its own character is very well done anyone worried that the film won't deliver by the end won't be disappointed either as the ending both makes sense and manages to be quite horrifying overall <UNK> is a truly great horror film and one of the best of the decade highly recommended viewing\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "c8gIzXncfaJK"
      },
      "source": [
        "### Creating One-hot word vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "B9W4yb3rv_E0"
      },
      "source": [
        "It is  common to use one-hot representation as input in Natural Language Processing tasks. In Keras, the Embedding layer takes an index as an input and convert it to one-hot vector with the length of the vocabulary size. Then multiplies these vectors by a normal weight matrix. But there is no way to only get a one-hot vector as the output of a layer in Keras. To solve this we use Lambda() layer and a function that creates the one-hot layer. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RPO_pK9zH4C5",
        "colab": {}
      },
      "source": [
        "def OneHot(input_dim=None, input_length=None):\n",
        "    \n",
        "    if input_dim is None or input_length is None:\n",
        "        raise TypeError(\"input_dim or input_length is not set\")\n",
        "\n",
        "    \n",
        "    def _one_hot(x, num_classes):\n",
        "        return K.one_hot(K.cast(x, 'uint8'),\n",
        "                          num_classes=num_classes)\n",
        "\n",
        "    return Lambda(_one_hot,\n",
        "                  arguments={'num_classes': input_dim},\n",
        "                  input_shape=(input_length,))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "364d3MAw0ez9"
      },
      "source": [
        "input_dim refers to the length of the one-hot vector and input_length refers to the length of the input sequence. Since the input to K.one_hot should be an integer tensor, we cast x to one (Keras passes around float tensors by default).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VHz76GNA2M4r"
      },
      "source": [
        " Each text sequence has in most cases different length of words. Here, we fill sequences with a pad token (0) to fit the size. This special tokens is then masked not to be accounted in averaging, loss calculation etc. We set the maximum length to 256."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9G_o7PsvgSFt"
      },
      "source": [
        "### Preparing input data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jiFn7sd_wF5j",
        "colab": {}
      },
      "source": [
        "VOCAB_SIZE = 10000\n",
        "MAX_SEQUENCE_LENGTH = 256\n",
        "\n",
        "X_train_enc = keras.preprocessing.sequence.pad_sequences(X_train,\n",
        "                                                        value=word_index[\"<PAD>\"],\n",
        "                                                        padding='post',\n",
        "                                                        maxlen=256)\n",
        "\n",
        "X_test_enc = keras.preprocessing.sequence.pad_sequences(X_test,\n",
        "                                                       value=word_index[\"<PAD>\"],\n",
        "                                                       padding='post',\n",
        "                                                       maxlen=256)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kcjFH1wKF_7d"
      },
      "source": [
        "And to view a padded review:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zwH4dcfW_a18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "outputId": "aeff975f-ca00-4bd2-8b04-628ad924c727"
      },
      "source": [
        "print(X_train_enc[1])\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[   1  194 1153  194 8255   78  228    5    6 1463 4369 5012  134   26\n",
            "    4  715    8  118 1634   14  394   20   13  119  954  189  102    5\n",
            "  207  110 3103   21   14   69  188    8   30   23    7    4  249  126\n",
            "   93    4  114    9 2300 1523    5  647    4  116    9   35 8163    4\n",
            "  229    9  340 1322    4  118    9    4  130 4901   19    4 1002    5\n",
            "   89   29  952   46   37    4  455    9   45   43   38 1543 1905  398\n",
            "    4 1649   26 6853    5  163   11 3215    2    4 1153    9  194  775\n",
            "    7 8255    2  349 2637  148  605    2 8003   15  123  125   68    2\n",
            " 6853   15  349  165 4362   98    5    4  228    9   43    2 1157   15\n",
            "  299  120    5  120  174   11  220  175  136   50    9 4373  228 8255\n",
            "    5    2  656  245 2350    5    4 9837  131  152  491   18    2   32\n",
            " 7464 1212   14    9    6  371   78   22  625   64 1382    9    8  168\n",
            "  145   23    4 1690   15   16    4 1355    5   28    6   52  154  462\n",
            "   33   89   78  285   16  145   95    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "F1zcxFwNGepA"
      },
      "source": [
        "Now we want to build the neural network model. We  are going to have a hidden layer with 16 hidden units. \n",
        "\n",
        "First, we want to transform each index to an embedded vector and then average all vectors to a single one. It has been showed that unweighted average of word vectors outperforms many complicated networks that model semantic and syntactic compositionality. As an example you can take a look at this: (http://anthology.aclweb.org/P/P15/P15-1162.pdf)\n",
        "\n",
        "To average we need to ignore padded zeros:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Yi04MLIvJOGZ",
        "colab": {}
      },
      "source": [
        "class GlobalAveragePooling1DMasked(GlobalAveragePooling1D):\n",
        "    def call(self, x, mask=None):\n",
        "        if mask != None:\n",
        "            return K.sum(x, axis=1) / K.sum(mask, axis=1)\n",
        "        else:\n",
        "            return super().call(x)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "whgIIB5ggjna"
      },
      "source": [
        "### Neural Network model using one-hot vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jlOLnlnSJgrU"
      },
      "source": [
        "The first layer is an one-hot layer. The second layer is to compute average on all word vectors in a sentence without considering padding. The  output vector is piped through a fully-connected layer. The last layer is connected with a single output node with the sigmoid activation function. The final value is a float between 0 and 1. \n",
        "The vocabulary count of the movie reviews (10000) is used as the input shape. At the end we visualize the model summary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_Pn83gBbxiK7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "9e3623d7-1d5a-4c8c-e945-2a30ba494a38"
      },
      "source": [
        "# put your code here\n",
        "model = Sequential()\n",
        "model.add(OneHot(VOCAB_SIZE,input_length=MAX_SEQUENCE_LENGTH))\n",
        "model.add(GlobalAveragePooling1D())\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lambda_1 (Lambda)            (None, 256, 10000)        0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_1 ( (None, 10000)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 10001     \n",
            "=================================================================\n",
            "Total params: 10,001\n",
            "Trainable params: 10,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_Mz96xpCgvTj"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "F3HbW_IKLqwT"
      },
      "source": [
        "To compile the model we need a loss function and an optimizer. We use binary_crossentropy loss function which is just a special case of categorical cross entropy. We also use Adam optimizer that can be used instead of the classical stochastic gradient descent procedure to update network weights iterative based in training data. You can read more about it here:\n",
        "(https://arxiv.org/abs/1412.6980v8\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qh1PWTNMxjUw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "6ca6a5e1-dd85-43a2-f65c-4581d0714f87"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "E1jwQQqCN5Ia"
      },
      "source": [
        "When training, we want to check the accuracy of the model on data it hasn't seen before. So we create a validation set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f5lAqzQlxjSM",
        "colab": {}
      },
      "source": [
        "X_val = np.array(X_train_enc[:10000])\n",
        "partial_X_train = np.array(X_train_enc[10000:])\n",
        "\n",
        "y_val = np.array(y_train[:10000])\n",
        "partial_y_train = np.array(y_train[10000:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "E8Kpo5G3OJEY"
      },
      "source": [
        "Then we start to train the model for 40 epochs in mini-batches of 512 samples and monitor the model's loss and accuracy on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "99_z39KAxjPi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "077b3a61-76e2-4521-9658-241d6bcdd9bb"
      },
      "source": [
        "history = model.fit(partial_X_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=40,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    verbose=1)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 15000 samples, validate on 10000 samples\n",
            "Epoch 1/40\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "15000/15000 [==============================] - 7s 478us/step - loss: 0.6930 - acc: 0.5039 - val_loss: 0.6928 - val_acc: 0.4963\n",
            "Epoch 2/40\n",
            "15000/15000 [==============================] - 6s 402us/step - loss: 0.6926 - acc: 0.5103 - val_loss: 0.6925 - val_acc: 0.5095\n",
            "Epoch 3/40\n",
            "15000/15000 [==============================] - 6s 405us/step - loss: 0.6922 - acc: 0.5291 - val_loss: 0.6921 - val_acc: 0.5305\n",
            "Epoch 4/40\n",
            "15000/15000 [==============================] - 6s 407us/step - loss: 0.6918 - acc: 0.5845 - val_loss: 0.6917 - val_acc: 0.6004\n",
            "Epoch 5/40\n",
            "15000/15000 [==============================] - 6s 408us/step - loss: 0.6914 - acc: 0.6161 - val_loss: 0.6913 - val_acc: 0.6173\n",
            "Epoch 6/40\n",
            "15000/15000 [==============================] - 6s 410us/step - loss: 0.6910 - acc: 0.6635 - val_loss: 0.6909 - val_acc: 0.6653\n",
            "Epoch 7/40\n",
            "15000/15000 [==============================] - 6s 409us/step - loss: 0.6906 - acc: 0.6510 - val_loss: 0.6906 - val_acc: 0.6370\n",
            "Epoch 8/40\n",
            "15000/15000 [==============================] - 6s 411us/step - loss: 0.6902 - acc: 0.6255 - val_loss: 0.6903 - val_acc: 0.6011\n",
            "Epoch 9/40\n",
            "15000/15000 [==============================] - 6s 412us/step - loss: 0.6898 - acc: 0.6022 - val_loss: 0.6899 - val_acc: 0.6198\n",
            "Epoch 10/40\n",
            "15000/15000 [==============================] - 6s 413us/step - loss: 0.6894 - acc: 0.6434 - val_loss: 0.6895 - val_acc: 0.6519\n",
            "Epoch 11/40\n",
            "15000/15000 [==============================] - 6s 413us/step - loss: 0.6890 - acc: 0.6650 - val_loss: 0.6891 - val_acc: 0.6525\n",
            "Epoch 12/40\n",
            "15000/15000 [==============================] - 6s 413us/step - loss: 0.6886 - acc: 0.6616 - val_loss: 0.6888 - val_acc: 0.6558\n",
            "Epoch 13/40\n",
            "15000/15000 [==============================] - 6s 414us/step - loss: 0.6882 - acc: 0.6619 - val_loss: 0.6884 - val_acc: 0.6617\n",
            "Epoch 14/40\n",
            "15000/15000 [==============================] - 6s 415us/step - loss: 0.6878 - acc: 0.6673 - val_loss: 0.6880 - val_acc: 0.6642\n",
            "Epoch 15/40\n",
            "15000/15000 [==============================] - 6s 415us/step - loss: 0.6874 - acc: 0.6720 - val_loss: 0.6877 - val_acc: 0.6650\n",
            "Epoch 16/40\n",
            "15000/15000 [==============================] - 6s 418us/step - loss: 0.6870 - acc: 0.6760 - val_loss: 0.6873 - val_acc: 0.6652\n",
            "Epoch 17/40\n",
            "15000/15000 [==============================] - 6s 417us/step - loss: 0.6867 - acc: 0.6733 - val_loss: 0.6870 - val_acc: 0.6668\n",
            "Epoch 18/40\n",
            "15000/15000 [==============================] - 6s 418us/step - loss: 0.6863 - acc: 0.6703 - val_loss: 0.6866 - val_acc: 0.6634\n",
            "Epoch 19/40\n",
            "15000/15000 [==============================] - 6s 418us/step - loss: 0.6859 - acc: 0.6695 - val_loss: 0.6862 - val_acc: 0.6655\n",
            "Epoch 20/40\n",
            "15000/15000 [==============================] - 6s 417us/step - loss: 0.6855 - acc: 0.6761 - val_loss: 0.6859 - val_acc: 0.6669\n",
            "Epoch 21/40\n",
            "15000/15000 [==============================] - 6s 417us/step - loss: 0.6851 - acc: 0.6779 - val_loss: 0.6855 - val_acc: 0.6667\n",
            "Epoch 22/40\n",
            "15000/15000 [==============================] - 6s 417us/step - loss: 0.6847 - acc: 0.6756 - val_loss: 0.6852 - val_acc: 0.6680\n",
            "Epoch 23/40\n",
            "15000/15000 [==============================] - 6s 417us/step - loss: 0.6844 - acc: 0.6778 - val_loss: 0.6848 - val_acc: 0.6679\n",
            "Epoch 24/40\n",
            "15000/15000 [==============================] - 6s 416us/step - loss: 0.6840 - acc: 0.6793 - val_loss: 0.6845 - val_acc: 0.6686\n",
            "Epoch 25/40\n",
            "15000/15000 [==============================] - 6s 417us/step - loss: 0.6836 - acc: 0.6781 - val_loss: 0.6841 - val_acc: 0.6680\n",
            "Epoch 26/40\n",
            "15000/15000 [==============================] - 6s 415us/step - loss: 0.6832 - acc: 0.6785 - val_loss: 0.6838 - val_acc: 0.6689\n",
            "Epoch 27/40\n",
            "15000/15000 [==============================] - 6s 416us/step - loss: 0.6829 - acc: 0.6799 - val_loss: 0.6834 - val_acc: 0.6692\n",
            "Epoch 28/40\n",
            "15000/15000 [==============================] - 6s 418us/step - loss: 0.6825 - acc: 0.6786 - val_loss: 0.6831 - val_acc: 0.6689\n",
            "Epoch 29/40\n",
            "15000/15000 [==============================] - 6s 418us/step - loss: 0.6821 - acc: 0.6781 - val_loss: 0.6828 - val_acc: 0.6676\n",
            "Epoch 30/40\n",
            "15000/15000 [==============================] - 6s 417us/step - loss: 0.6818 - acc: 0.6787 - val_loss: 0.6824 - val_acc: 0.6707\n",
            "Epoch 31/40\n",
            "15000/15000 [==============================] - 6s 417us/step - loss: 0.6814 - acc: 0.6788 - val_loss: 0.6821 - val_acc: 0.6690\n",
            "Epoch 32/40\n",
            "15000/15000 [==============================] - 6s 418us/step - loss: 0.6810 - acc: 0.6801 - val_loss: 0.6817 - val_acc: 0.6702\n",
            "Epoch 33/40\n",
            "15000/15000 [==============================] - 6s 418us/step - loss: 0.6807 - acc: 0.6813 - val_loss: 0.6814 - val_acc: 0.6704\n",
            "Epoch 34/40\n",
            "15000/15000 [==============================] - 6s 416us/step - loss: 0.6803 - acc: 0.6807 - val_loss: 0.6811 - val_acc: 0.6721\n",
            "Epoch 35/40\n",
            "15000/15000 [==============================] - 6s 418us/step - loss: 0.6799 - acc: 0.6791 - val_loss: 0.6808 - val_acc: 0.6708\n",
            "Epoch 36/40\n",
            "15000/15000 [==============================] - 6s 417us/step - loss: 0.6796 - acc: 0.6801 - val_loss: 0.6804 - val_acc: 0.6710\n",
            "Epoch 37/40\n",
            "15000/15000 [==============================] - 6s 416us/step - loss: 0.6792 - acc: 0.6807 - val_loss: 0.6800 - val_acc: 0.6722\n",
            "Epoch 38/40\n",
            "15000/15000 [==============================] - 6s 418us/step - loss: 0.6789 - acc: 0.6799 - val_loss: 0.6797 - val_acc: 0.6729\n",
            "Epoch 39/40\n",
            "15000/15000 [==============================] - 6s 418us/step - loss: 0.6785 - acc: 0.6815 - val_loss: 0.6794 - val_acc: 0.6709\n",
            "Epoch 40/40\n",
            "15000/15000 [==============================] - 6s 417us/step - loss: 0.6782 - acc: 0.6818 - val_loss: 0.6790 - val_acc: 0.6711\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "i_9a_rybhG5J"
      },
      "source": [
        "### Evaluating the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EYLH8kOgOo9W"
      },
      "source": [
        "To evaulate the model on test data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CFMt2Q7b3taP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "03ae708a-ef54-4305-c9e2-151314167619"
      },
      "source": [
        "results = model.evaluate(X_test_enc, y_test)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 7s 270us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9RrKiPHcAmQU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "419d4fe7-80ef-45c9-8b45-40ae95e1f744"
      },
      "source": [
        "print(results)\n",
        "# loss, accuracay "
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.6787935314750672, 0.6778]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pW7IpHxMO6qp"
      },
      "source": [
        "Our first model accuracy using one-hot vectors is \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OwZk_yoWhPJB"
      },
      "source": [
        "### Plotting the accuracy graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JIDPH1J7PMzN"
      },
      "source": [
        "To plot a graph of accuracy and loss over time we can use Matplotlib:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LS9k2vvSAqB7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "8faf5892-0189-46d3-ed3e-783fc9e8234a"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history_dict = history.history\n",
        "\n",
        "acc = history_dict['acc']\n",
        "val_acc = history_dict['val_acc']\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QCewvf_1yD0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "64e8d39f-4a38-4f31-bd4c-823bc74a869c"
      },
      "source": [
        "VOCAB_SIZE"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "a7OwOQw4h8RX"
      },
      "source": [
        "### Neural Network model using word embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "l-QzOMO_P4jc"
      },
      "source": [
        "Now instead of one-hot vectors, we want to use embedding. We change our first layer in model1 to an Embedding layer. This layer takes the integer-encoded vocabulary and looks up the embedding vector for each word-index. These vectors are learned as the model trains. The vectors add a dimension to the output array. The resulting dimensions are: (batch, sequence, embedding)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MFrCsL-NBFVL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8b0d630c-025f-4f26-9995-5549d6ec0795"
      },
      "source": [
        "VOCAB_SIZE= 10000\n",
        "model2 = Sequential()\n",
        "model2.add(Embedding(VOCAB_SIZE,16,input_length=MAX_SEQUENCE_LENGTH))\n",
        "model2.add(GlobalAveragePooling1D())\n",
        "model2.add(Dense(1,activation='sigmoid'))\n",
        "# put the code here\n",
        "\n",
        "model2.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "X_val = np.array(X_train_enc[:10000])\n",
        "partial_X_train = np.array(X_train_enc[10000:])\n",
        "\n",
        "history2 = model2.fit(partial_X_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=40,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    verbose=1)\n",
        "\n",
        "results = model2.evaluate(X_test_enc, y_test)\n",
        "print(results)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15000 samples, validate on 10000 samples\n",
            "Epoch 1/40\n",
            "15000/15000 [==============================] - 0s 23us/step - loss: 0.6919 - acc: 0.6141 - val_loss: 0.6905 - val_acc: 0.6891\n",
            "Epoch 2/40\n",
            "15000/15000 [==============================] - 0s 11us/step - loss: 0.6885 - acc: 0.7282 - val_loss: 0.6869 - val_acc: 0.7310\n",
            "Epoch 3/40\n",
            "15000/15000 [==============================] - 0s 12us/step - loss: 0.6839 - acc: 0.7435 - val_loss: 0.6821 - val_acc: 0.7318\n",
            "Epoch 4/40\n",
            "15000/15000 [==============================] - 0s 12us/step - loss: 0.6780 - acc: 0.7475 - val_loss: 0.6761 - val_acc: 0.7392\n",
            "Epoch 5/40\n",
            "15000/15000 [==============================] - 0s 11us/step - loss: 0.6706 - acc: 0.7547 - val_loss: 0.6687 - val_acc: 0.7413\n",
            "Epoch 6/40\n",
            "15000/15000 [==============================] - 0s 11us/step - loss: 0.6619 - acc: 0.7621 - val_loss: 0.6603 - val_acc: 0.7471\n",
            "Epoch 7/40\n",
            "15000/15000 [==============================] - 0s 11us/step - loss: 0.6521 - acc: 0.7647 - val_loss: 0.6510 - val_acc: 0.7513\n",
            "Epoch 8/40\n",
            "15000/15000 [==============================] - 0s 11us/step - loss: 0.6414 - acc: 0.7681 - val_loss: 0.6410 - val_acc: 0.7550\n",
            "Epoch 9/40\n",
            "15000/15000 [==============================] - 0s 12us/step - loss: 0.6299 - acc: 0.7729 - val_loss: 0.6304 - val_acc: 0.7605\n",
            "Epoch 10/40\n",
            "15000/15000 [==============================] - 0s 12us/step - loss: 0.6179 - acc: 0.7793 - val_loss: 0.6193 - val_acc: 0.7658\n",
            "Epoch 11/40\n",
            "15000/15000 [==============================] - 0s 11us/step - loss: 0.6055 - acc: 0.7845 - val_loss: 0.6081 - val_acc: 0.7693\n",
            "Epoch 12/40\n",
            "15000/15000 [==============================] - 0s 12us/step - loss: 0.5931 - acc: 0.7905 - val_loss: 0.5967 - val_acc: 0.7762\n",
            "Epoch 13/40\n",
            "15000/15000 [==============================] - 0s 11us/step - loss: 0.5804 - acc: 0.7971 - val_loss: 0.5855 - val_acc: 0.7819\n",
            "Epoch 14/40\n",
            "15000/15000 [==============================] - 0s 13us/step - loss: 0.5678 - acc: 0.8031 - val_loss: 0.5741 - val_acc: 0.7869\n",
            "Epoch 15/40\n",
            "15000/15000 [==============================] - 0s 12us/step - loss: 0.5553 - acc: 0.8079 - val_loss: 0.5629 - val_acc: 0.7929\n",
            "Epoch 16/40\n",
            "15000/15000 [==============================] - 0s 12us/step - loss: 0.5428 - acc: 0.8144 - val_loss: 0.5519 - val_acc: 0.7978\n",
            "Epoch 17/40\n",
            "15000/15000 [==============================] - 0s 12us/step - loss: 0.5306 - acc: 0.8217 - val_loss: 0.5410 - val_acc: 0.8032\n",
            "Epoch 18/40\n",
            "15000/15000 [==============================] - 0s 12us/step - loss: 0.5187 - acc: 0.8271 - val_loss: 0.5304 - val_acc: 0.8083\n",
            "Epoch 19/40\n",
            "15000/15000 [==============================] - 0s 11us/step - loss: 0.5071 - acc: 0.8309 - val_loss: 0.5202 - val_acc: 0.8133\n",
            "Epoch 20/40\n",
            "15000/15000 [==============================] - 0s 12us/step - loss: 0.4958 - acc: 0.8361 - val_loss: 0.5102 - val_acc: 0.8171\n",
            "Epoch 21/40\n",
            "15000/15000 [==============================] - 0s 11us/step - loss: 0.4849 - acc: 0.8411 - val_loss: 0.5005 - val_acc: 0.8210\n",
            "Epoch 22/40\n",
            "15000/15000 [==============================] - 0s 11us/step - loss: 0.4743 - acc: 0.8445 - val_loss: 0.4914 - val_acc: 0.8250\n",
            "Epoch 23/40\n",
            "15000/15000 [==============================] - 0s 12us/step - loss: 0.4641 - acc: 0.8494 - val_loss: 0.4823 - val_acc: 0.8294\n",
            "Epoch 24/40\n",
            "15000/15000 [==============================] - 0s 12us/step - loss: 0.4542 - acc: 0.8531 - val_loss: 0.4737 - val_acc: 0.8314\n",
            "Epoch 25/40\n",
            "15000/15000 [==============================] - 0s 12us/step - loss: 0.4447 - acc: 0.8569 - val_loss: 0.4655 - val_acc: 0.8338\n",
            "Epoch 26/40\n",
            "15000/15000 [==============================] - 0s 12us/step - loss: 0.4357 - acc: 0.8595 - val_loss: 0.4576 - val_acc: 0.8358\n",
            "Epoch 27/40\n",
            "15000/15000 [==============================] - 0s 12us/step - loss: 0.4269 - acc: 0.8627 - val_loss: 0.4501 - val_acc: 0.8386\n",
            "Epoch 28/40\n",
            "15000/15000 [==============================] - 0s 11us/step - loss: 0.4184 - acc: 0.8647 - val_loss: 0.4430 - val_acc: 0.8423\n",
            "Epoch 29/40\n",
            "15000/15000 [==============================] - 0s 11us/step - loss: 0.4103 - acc: 0.8692 - val_loss: 0.4361 - val_acc: 0.8444\n",
            "Epoch 30/40\n",
            "15000/15000 [==============================] - 0s 11us/step - loss: 0.4025 - acc: 0.8725 - val_loss: 0.4295 - val_acc: 0.8464\n",
            "Epoch 31/40\n",
            "15000/15000 [==============================] - 0s 11us/step - loss: 0.3950 - acc: 0.8739 - val_loss: 0.4233 - val_acc: 0.8490\n",
            "Epoch 32/40\n",
            "15000/15000 [==============================] - 0s 11us/step - loss: 0.3879 - acc: 0.8761 - val_loss: 0.4173 - val_acc: 0.8497\n",
            "Epoch 33/40\n",
            "15000/15000 [==============================] - 0s 12us/step - loss: 0.3810 - acc: 0.8783 - val_loss: 0.4117 - val_acc: 0.8512\n",
            "Epoch 34/40\n",
            "15000/15000 [==============================] - 0s 12us/step - loss: 0.3744 - acc: 0.8800 - val_loss: 0.4063 - val_acc: 0.8526\n",
            "Epoch 35/40\n",
            "15000/15000 [==============================] - 0s 11us/step - loss: 0.3681 - acc: 0.8827 - val_loss: 0.4011 - val_acc: 0.8542\n",
            "Epoch 36/40\n",
            "15000/15000 [==============================] - 0s 11us/step - loss: 0.3619 - acc: 0.8843 - val_loss: 0.3961 - val_acc: 0.8563\n",
            "Epoch 37/40\n",
            "15000/15000 [==============================] - 0s 11us/step - loss: 0.3562 - acc: 0.8862 - val_loss: 0.3915 - val_acc: 0.8552\n",
            "Epoch 38/40\n",
            "15000/15000 [==============================] - 0s 12us/step - loss: 0.3504 - acc: 0.8879 - val_loss: 0.3870 - val_acc: 0.8571\n",
            "Epoch 39/40\n",
            "15000/15000 [==============================] - 0s 12us/step - loss: 0.3448 - acc: 0.8893 - val_loss: 0.3828 - val_acc: 0.8606\n",
            "Epoch 40/40\n",
            "15000/15000 [==============================] - 0s 12us/step - loss: 0.3395 - acc: 0.8909 - val_loss: 0.3787 - val_acc: 0.8599\n",
            "25000/25000 [==============================] - 1s 35us/step\n",
            "[0.3874320946025848, 0.85464]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I4zIPJDcTPq3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "5489a4e0-d216-4db2-ee60-40f0d58a841d"
      },
      "source": [
        "results = model2.evaluate(X_test_enc, y_test)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 1s 36us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "waS96edDTRyL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "f2dfbb6f-3c3d-435b-c24b-b21a5730a03f"
      },
      "source": [
        "print (results)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.3874320946025848, 0.85464]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XB7aveVzTC5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "27fcd326-b982-4433-ae95-795a1d365d86"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history_dict = history2.history\n",
        "\n",
        "acc = history_dict['acc']\n",
        "val_acc = history_dict['val_acc']\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npAQhIiIJKUGIiEhCShAiIpLQ/wOsinCvF5EyCgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7FBpTc_rXGvQ"
      },
      "source": [
        "The accuracy of model2 is 87%. Using Embedding layer instead of one-hot layer improved the performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "--020hfG6rN2"
      },
      "source": [
        "### Using pre-trained word embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J4gBeOyi4gkM"
      },
      "source": [
        "The Embedding layer can be used to load a pre-trained word embedding model. We are going to use GloVe embeddings, which you can read about it here (https://nlp.stanford.edu/projects/glove/). GloVe stands for \"Global Vectors for Word Representation\". It's a somewhat popular embedding technique based on factorizing a matrix of word co-occurence statistics. You can download GloVe and we can seed the Keras Embedding layer with weights from the pre-trained embedding for the words in your dataset.\n",
        "First, we need to read GloVe and map words to GloVe:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOsgGRXg77cq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import chakin\n",
        "# chakin.download(number=12, save_dir='./')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f_PypdqG9Iis",
        "colab": {}
      },
      "source": [
        "def readGloveFile(gloveFile):\n",
        "    with open(gloveFile, 'r') as f:\n",
        "        wordToGlove = {}  \n",
        "        wordToIndex = {}  \n",
        "        indexToWord = {}  \n",
        "\n",
        "        for line in f:\n",
        "            record = line.strip().split()\n",
        "            token = record[0] \n",
        "            wordToGlove[token] = np.array(record[1:], dtype=np.float64) \n",
        "            \n",
        "        tokens = sorted(wordToGlove.keys())\n",
        "        for idx, tok in enumerate(tokens):\n",
        "            kerasIdx = idx + 1  \n",
        "            wordToIndex[tok] = kerasIdx \n",
        "            indexToWord[kerasIdx] = tok \n",
        "\n",
        "    return wordToIndex, indexToWord, wordToGlove"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZcIZ3dq59bCh"
      },
      "source": [
        "Now, we create our pre-trained Embedding layer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gembn7VM3ex8",
        "colab": {}
      },
      "source": [
        "def createPretrainedEmbeddingLayer(wordToGlove, wordToIndex, isTrainable):\n",
        "    vocabLen = len(wordToIndex) + 1  \n",
        "    embDim = next(iter(wordToGlove.values())).shape[0]  \n",
        "   \n",
        "    embeddingMatrix = np.zeros((vocabLen, embDim))  \n",
        "    for word, index in wordToIndex.items():\n",
        "        embeddingMatrix[index, :] = wordToGlove[word] \n",
        "\n",
        "    embeddingLayer = Embedding(vocabLen, embDim, embeddings_initializer=Constant(embeddingMatrix), trainable=isTrainable)\n",
        "    return embeddingLayer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HGxciLK4-xOr"
      },
      "source": [
        "We freeze the weights. To create the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PZCPUM0W_Drc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "6a96de20-4f47-4939-ce6d-88a827e70486"
      },
      "source": [
        "# put the code here\n",
        "import os\n",
        "os.system(\"unzip './glove.6B.zip' \")\n",
        "from tensorflow.contrib.keras.api.keras.initializers import Constant\n",
        "wordToIndex, indexToWord, wordToGlove = readGloveFile('./glove.6B.300d.txt')\n",
        "embeddingLayer = createPretrainedEmbeddingLayer(wordToGlove, wordToIndex, isTrainable=False)\n",
        "os.system(\"rm './glove.6B.zip'\")"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "M-bZ5SCHiIMl"
      },
      "source": [
        "### Adding another hidden layer to the network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZbZ6UBDfbjea"
      },
      "source": [
        "In model3, we only add another dense layer to see if that improves the performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Vw0le1YjDdCa",
        "colab": {}
      },
      "source": [
        "# put your code here\n",
        "model3 = Sequential()\n",
        "# model3.add(Embedding(VOCAB_SIZE,16,input_length=MAX_SEQUENCE_LENGTH))\n",
        "model3.add(embeddingLayer)\n",
        "model3.add(GlobalAveragePooling1D())\n",
        "model3.add(Dense(1,activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgiSSc-dI_05",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "08d46ef6-4728-418e-f971-0b795976cccc"
      },
      "source": [
        "model3.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "X_val = np.array(X_train_enc[:10000])\n",
        "partial_X_train = np.array(X_train_enc[10000:])\n",
        "\n",
        "history3 = model3.fit(partial_X_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=40,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    verbose=1)\n",
        "\n",
        "results = model3.evaluate(X_test_enc, y_test)\n",
        "print(results)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15000 samples, validate on 10000 samples\n",
            "Epoch 1/40\n",
            "15000/15000 [==============================] - 1s 43us/step - loss: 0.6469 - acc: 0.6499 - val_loss: 0.6490 - val_acc: 0.6423\n",
            "Epoch 2/40\n",
            "15000/15000 [==============================] - 0s 19us/step - loss: 0.6459 - acc: 0.6510 - val_loss: 0.6480 - val_acc: 0.6428\n",
            "Epoch 3/40\n",
            "15000/15000 [==============================] - 0s 19us/step - loss: 0.6451 - acc: 0.6511 - val_loss: 0.6472 - val_acc: 0.6415\n",
            "Epoch 4/40\n",
            "15000/15000 [==============================] - 0s 19us/step - loss: 0.6442 - acc: 0.6511 - val_loss: 0.6463 - val_acc: 0.6457\n",
            "Epoch 5/40\n",
            "15000/15000 [==============================] - 0s 19us/step - loss: 0.6432 - acc: 0.6541 - val_loss: 0.6455 - val_acc: 0.6473\n",
            "Epoch 6/40\n",
            "15000/15000 [==============================] - 0s 19us/step - loss: 0.6424 - acc: 0.6551 - val_loss: 0.6453 - val_acc: 0.6472\n",
            "Epoch 7/40\n",
            "15000/15000 [==============================] - 0s 19us/step - loss: 0.6417 - acc: 0.6560 - val_loss: 0.6442 - val_acc: 0.6484\n",
            "Epoch 8/40\n",
            "15000/15000 [==============================] - 0s 19us/step - loss: 0.6408 - acc: 0.6556 - val_loss: 0.6432 - val_acc: 0.6496\n",
            "Epoch 9/40\n",
            "15000/15000 [==============================] - 0s 19us/step - loss: 0.6400 - acc: 0.6581 - val_loss: 0.6425 - val_acc: 0.6508\n",
            "Epoch 10/40\n",
            "15000/15000 [==============================] - 0s 19us/step - loss: 0.6391 - acc: 0.6596 - val_loss: 0.6418 - val_acc: 0.6520\n",
            "Epoch 11/40\n",
            "15000/15000 [==============================] - 0s 18us/step - loss: 0.6383 - acc: 0.6603 - val_loss: 0.6410 - val_acc: 0.6542\n",
            "Epoch 12/40\n",
            "15000/15000 [==============================] - 0s 19us/step - loss: 0.6376 - acc: 0.6624 - val_loss: 0.6405 - val_acc: 0.6533\n",
            "Epoch 13/40\n",
            "15000/15000 [==============================] - 0s 19us/step - loss: 0.6368 - acc: 0.6607 - val_loss: 0.6397 - val_acc: 0.6548\n",
            "Epoch 14/40\n",
            "15000/15000 [==============================] - 0s 19us/step - loss: 0.6361 - acc: 0.6650 - val_loss: 0.6390 - val_acc: 0.6554\n",
            "Epoch 15/40\n",
            "15000/15000 [==============================] - 0s 19us/step - loss: 0.6353 - acc: 0.6640 - val_loss: 0.6388 - val_acc: 0.6562\n",
            "Epoch 16/40\n",
            "15000/15000 [==============================] - 0s 19us/step - loss: 0.6347 - acc: 0.6631 - val_loss: 0.6379 - val_acc: 0.6577\n",
            "Epoch 17/40\n",
            "15000/15000 [==============================] - 0s 19us/step - loss: 0.6339 - acc: 0.6652 - val_loss: 0.6371 - val_acc: 0.6578\n",
            "Epoch 18/40\n",
            "15000/15000 [==============================] - 0s 19us/step - loss: 0.6333 - acc: 0.6648 - val_loss: 0.6365 - val_acc: 0.6594\n",
            "Epoch 19/40\n",
            "15000/15000 [==============================] - 0s 19us/step - loss: 0.6326 - acc: 0.6669 - val_loss: 0.6358 - val_acc: 0.6597\n",
            "Epoch 20/40\n",
            "15000/15000 [==============================] - 0s 19us/step - loss: 0.6319 - acc: 0.6677 - val_loss: 0.6353 - val_acc: 0.6616\n",
            "Epoch 21/40\n",
            "15000/15000 [==============================] - 0s 19us/step - loss: 0.6313 - acc: 0.6677 - val_loss: 0.6347 - val_acc: 0.6618\n",
            "Epoch 22/40\n",
            "15000/15000 [==============================] - 0s 19us/step - loss: 0.6306 - acc: 0.6678 - val_loss: 0.6339 - val_acc: 0.6632\n",
            "Epoch 23/40\n",
            "15000/15000 [==============================] - 0s 19us/step - loss: 0.6300 - acc: 0.6683 - val_loss: 0.6333 - val_acc: 0.6634\n",
            "Epoch 24/40\n",
            "15000/15000 [==============================] - 0s 19us/step - loss: 0.6292 - acc: 0.6695 - val_loss: 0.6327 - val_acc: 0.6642\n",
            "Epoch 25/40\n",
            "15000/15000 [==============================] - 0s 19us/step - loss: 0.6286 - acc: 0.6717 - val_loss: 0.6325 - val_acc: 0.6655\n",
            "Epoch 26/40\n",
            "15000/15000 [==============================] - 0s 19us/step - loss: 0.6281 - acc: 0.6709 - val_loss: 0.6317 - val_acc: 0.6660\n",
            "Epoch 27/40\n",
            "15000/15000 [==============================] - 0s 19us/step - loss: 0.6275 - acc: 0.6715 - val_loss: 0.6311 - val_acc: 0.6664\n",
            "Epoch 28/40\n",
            "15000/15000 [==============================] - 0s 19us/step - loss: 0.6268 - acc: 0.6715 - val_loss: 0.6305 - val_acc: 0.6674\n",
            "Epoch 29/40\n",
            "15000/15000 [==============================] - 0s 19us/step - loss: 0.6264 - acc: 0.6715 - val_loss: 0.6302 - val_acc: 0.6678\n",
            "Epoch 30/40\n",
            "15000/15000 [==============================] - 0s 19us/step - loss: 0.6256 - acc: 0.6723 - val_loss: 0.6296 - val_acc: 0.6678\n",
            "Epoch 31/40\n",
            "15000/15000 [==============================] - 0s 19us/step - loss: 0.6250 - acc: 0.6733 - val_loss: 0.6290 - val_acc: 0.6692\n",
            "Epoch 32/40\n",
            "15000/15000 [==============================] - 0s 19us/step - loss: 0.6245 - acc: 0.6743 - val_loss: 0.6285 - val_acc: 0.6689\n",
            "Epoch 33/40\n",
            "15000/15000 [==============================] - 0s 19us/step - loss: 0.6239 - acc: 0.6740 - val_loss: 0.6279 - val_acc: 0.6700\n",
            "Epoch 34/40\n",
            "15000/15000 [==============================] - 0s 19us/step - loss: 0.6233 - acc: 0.6742 - val_loss: 0.6276 - val_acc: 0.6697\n",
            "Epoch 35/40\n",
            "15000/15000 [==============================] - 0s 19us/step - loss: 0.6228 - acc: 0.6758 - val_loss: 0.6270 - val_acc: 0.6707\n",
            "Epoch 36/40\n",
            "15000/15000 [==============================] - 0s 19us/step - loss: 0.6222 - acc: 0.6769 - val_loss: 0.6266 - val_acc: 0.6713\n",
            "Epoch 37/40\n",
            "15000/15000 [==============================] - 0s 19us/step - loss: 0.6217 - acc: 0.6765 - val_loss: 0.6260 - val_acc: 0.6717\n",
            "Epoch 38/40\n",
            "15000/15000 [==============================] - 0s 19us/step - loss: 0.6212 - acc: 0.6773 - val_loss: 0.6254 - val_acc: 0.6735\n",
            "Epoch 39/40\n",
            "15000/15000 [==============================] - 0s 20us/step - loss: 0.6206 - acc: 0.6777 - val_loss: 0.6249 - val_acc: 0.6741\n",
            "Epoch 40/40\n",
            "15000/15000 [==============================] - 0s 19us/step - loss: 0.6201 - acc: 0.6802 - val_loss: 0.6248 - val_acc: 0.6710\n",
            "25000/25000 [==============================] - 1s 36us/step\n",
            "[0.625195871181488, 0.66732]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vSN29uCKQ_L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "outputId": "da9423c7-c4a1-4a22-a496-2f0672db6c88"
      },
      "source": [
        "results = model3.evaluate(X_test_enc, y_test)\n",
        "print(results)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 1s 37us/step\n",
            "[0.625195871181488, 0.66732]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QtsdVeW7UgCu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "42f432f8-4756-4636-9ec5-fc0345a29ba8"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history_dict = history3.history\n",
        "\n",
        "acc = history_dict['acc']\n",
        "val_acc = history_dict['val_acc']\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Kx--Ytk3ZbLo"
      },
      "source": [
        "The accuracy of model3 with an additional layer is 85%. Adding more layers can help you to extract more features. But we can do that upto a certain extent. After some point, instead of extracting features, we tend to overfit the data. Overfitting can lead to errors in some or the other form like false positives. It is not easy to choose the number of units in a hidden layer or the number of hidden layers in a neural network. For many applications, one hidden layer is enough. As a general rule, the number of units in that hidden layer is between the number of inputs and the number of outputs.\n",
        " The best way to decide on the number of units and hidden layers is to try various parameters. Train several neural networks with different numbers of hidden layers and neurons, and monitor the performance of them. You will have to experiment using a series of different architectures. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gn2GSV4ioyO2"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XYC6DykEox2w",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GsCJ01StlgCx"
      },
      "source": [
        "This tutorial is substantially based on this document:\n",
        "https://www.tensorflow.org/tutorials/keras/basic_text_classification\n",
        "\n",
        "To read more about Sequential APIs you can go to: https://keras.io/getting-started/sequential-model-guide/\n",
        "\n",
        "The one-hot word vector layer is taken from:\n",
        "https://fdalvi.github.io/blog/2018-04-07-keras-sequential-onehot/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jL0UovfaE9GE",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}