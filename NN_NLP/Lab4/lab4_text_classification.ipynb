{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hExKCzh6doIW"
   },
   "source": [
    "# Lab 4 - Neural Network Classifier Using Simple Word Embeddings\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HixoFOoCIJ7V"
   },
   "source": [
    "In this session, we demonstrate how to solve a text classification task using simple \n",
    "feedforward neural network classifier. We will use IMDB Large Movie Review Dataset to train a binary classification model, able to predict whether a review is positive or negative. First, our network takes one-hot word vectors as input, averages them to make one vector and trains a \n",
    "fully-connected layer to predict the output. In the second part, we replace the one-hot vectors with the word embeddings and add a layer to see how much that improves the performance.\n",
    "\n",
    "We are going to use Keras Sequential API in this session. The Sequential API allows you to make models layer-by-layer. But it is not straightforward to define models where layers connect to more than just the previous and next layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m8fpBfhBpupy"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from keras.layers import Lambda, GlobalAveragePooling1D, Dense, Embedding\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cqvPQvgvPv1W"
   },
   "source": [
    "### Downloading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EundMtGPpCdf"
   },
   "source": [
    "The dataset we will be using is the IMDB Large Movie Review Dataset, which consists of 50000 labeled movie reviews. These are split into 25,000 reviews for training and 25,000 reviews for testing. The  dataset contains an even number of positive and negative reviews, so randomly guessing yields 50% accuracy. The data is preprocessed. For text classification, it is ususal to limit the size of the vocabulary to stop the dataset from becoming too sparse, creating possible overfitting. We keep the top 10,000 most frequently occurring words in the training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NyuSzkafqNca"
   },
   "outputs": [],
   "source": [
    "imdb = keras.datasets.imdb\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6U4iCV9-rmay"
   },
   "source": [
    "We now can start playing around with the data, letâ€™s first see the length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "h-gjWRAuqg5s",
    "outputId": "42a11476-4bb4-438d-ac95-2bc45363229d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training entries: 25000, labels: 25000\n"
     ]
    }
   ],
   "source": [
    "print(\"Training entries: {}, labels: {}\".format(len(X_train), len(y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MTRZrpcyr-4x"
   },
   "source": [
    "The  reviews have been converted to integers and each integer represents a  word in a dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "79Ev72Kgq4XL"
   },
   "outputs": [],
   "source": [
    " X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tvuu4KhStqei"
   },
   "source": [
    "We can convert integers back to words by querying a dictionary object that contains the integer to string mapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gMCH1OoDrSNR"
   },
   "outputs": [],
   "source": [
    "\n",
    "word_index = imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5IreFXgruZot"
   },
   "source": [
    "Index 1 represents the beginning of the sentence and the index 2 is assigned to all unknown tokens. Index 0 will be used for padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "abIb7Fe5u3GQ"
   },
   "outputs": [],
   "source": [
    "\n",
    "word_index = {k:(v+3) for k,v in word_index.items()}\n",
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2  \n",
    "word_index[\"<UNUSED>\"] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9TnnSuspvC5b"
   },
   "source": [
    "To reverse key and values in a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nKOiVVXQu-_I"
   },
   "outputs": [],
   "source": [
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZmTJEm8xvUvW"
   },
   "source": [
    "To view a word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "SqN5jgVKvJJZ",
    "outputId": "71c8ab13-e4f1-4204-ec4d-f415765b7a60"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you'"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_word_index[25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q6QjrzgVvrYn"
   },
   "source": [
    "And to recreate the whole sentence from our training data we define decode_review:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wvrKeMgxvWlv"
   },
   "outputs": [],
   "source": [
    "def decode_review(text):\n",
    "    return ' '.join([reverse_word_index.get(i, '?') for i in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sxg4YA_NvdRg"
   },
   "outputs": [],
   "source": [
    "decode_review(X_train[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c8gIzXncfaJK"
   },
   "source": [
    "### Creating One-hot word vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B9W4yb3rv_E0"
   },
   "source": [
    "It is  common to use one-hot representation as input in Natural Language Processing tasks. In Keras, the Embedding layer takes an index as an input and convert it to one-hot vector with the length of the vocabulary size. Then multiplies these vectors by a normal weight matrix. But there is no way to only get a one-hot vector as the output of a layer in Keras. To solve this we use Lambda() layer and a function that creates the one-hot layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RPO_pK9zH4C5"
   },
   "outputs": [],
   "source": [
    "def OneHot(input_dim=None, input_length=None):\n",
    "    \n",
    "    if input_dim is None or input_length is None:\n",
    "        raise TypeError(\"input_dim or input_length is not set\")\n",
    "\n",
    "    \n",
    "    def _one_hot(x, num_classes):\n",
    "        return K.one_hot(K.cast(x, 'uint8'),\n",
    "                          num_classes=num_classes)\n",
    "\n",
    "    return Lambda(_one_hot,\n",
    "                  arguments={'num_classes': input_dim},\n",
    "                  input_shape=(input_length,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "364d3MAw0ez9"
   },
   "source": [
    "input_dim refers to the length of the one-hot vector and input_length refers to the length of the input sequence. Since the input to K.one_hot should be an integer tensor, we cast x to one (Keras passes around float tensors by default).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VHz76GNA2M4r"
   },
   "source": [
    " Each text sequence has in most cases different length of words. Here, we fill sequences with a pad token (0) to fit the size. This special tokens is then masked not to be accounted in averaging, loss calculation etc. We set the maximum length to 256."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9G_o7PsvgSFt"
   },
   "source": [
    "### Preparing input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jiFn7sd_wF5j"
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 10000\n",
    "MAX_SEQUENCE_LENGTH = 256\n",
    "\n",
    "X_train_enc = keras.preprocessing.sequence.pad_sequences(X_train,\n",
    "                                                        value=word_index[\"<PAD>\"],\n",
    "                                                        padding='post',\n",
    "                                                        maxlen=256)\n",
    "\n",
    "X_test_enc = keras.preprocessing.sequence.pad_sequences(X_test,\n",
    "                                                       value=word_index[\"<PAD>\"],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kcjFH1wKF_7d"
   },
   "source": [
    "And to view a padded review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "colab_type": "code",
    "id": "zwH4dcfW_a18",
    "outputId": "8410ee40-6936-4557-f3ac-2f865214f56f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1  194 1153  194 8255   78  228    5    6 1463 4369 5012  134   26\n",
      "    4  715    8  118 1634   14  394   20   13  119  954  189  102    5\n",
      "  207  110 3103   21   14   69  188    8   30   23    7    4  249  126\n",
      "   93    4  114    9 2300 1523    5  647    4  116    9   35 8163    4\n",
      "  229    9  340 1322    4  118    9    4  130 4901   19    4 1002    5\n",
      "   89   29  952   46   37    4  455    9   45   43   38 1543 1905  398\n",
      "    4 1649   26 6853    5  163   11 3215    2    4 1153    9  194  775\n",
      "    7 8255    2  349 2637  148  605    2 8003   15  123  125   68    2\n",
      " 6853   15  349  165 4362   98    5    4  228    9   43    2 1157   15\n",
      "  299  120    5  120  174   11  220  175  136   50    9 4373  228 8255\n",
      "    5    2  656  245 2350    5    4 9837  131  152  491   18    2   32\n",
      " 7464 1212   14    9    6  371   78   22  625   64 1382    9    8  168\n",
      "  145   23    4 1690   15   16    4 1355    5   28    6   52  154  462\n",
      "   33   89   78  285   16  145   95    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_enc[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F1zcxFwNGepA"
   },
   "source": [
    "Now we want to build the neural network model. We  are going to have a hidden layer with 16 hidden units. \n",
    "\n",
    "First, we want to transform each index to an embedded vector and then average all vectors to a single one. It has been showed that unweighted average of word vectors outperforms many complicated networks that model semantic and syntactic compositionality. As an example you can take a look at this: (http://anthology.aclweb.org/P/P15/P15-1162.pdf)\n",
    "\n",
    "To average we need to ignore padded zeros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yi04MLIvJOGZ"
   },
   "outputs": [],
   "source": [
    "class GlobalAveragePooling1DMasked(GlobalAveragePooling1D):\n",
    "    def call(self, x, mask=None):\n",
    "        if mask != None:\n",
    "            return K.sum(x, axis=1) / K.sum(mask, axis=1)\n",
    "        else:\n",
    "            return super().call(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "whgIIB5ggjna"
   },
   "source": [
    "### Neural Network model using one-hot vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jlOLnlnSJgrU"
   },
   "source": [
    "The first layer is an one-hot layer. The second layer is to compute average on all word vectors in a sentence without considering padding. The  output vector is piped through a fully-connected layer. The last layer is connected with a single output node with the sigmoid activation function. The final value is a float between 0 and 1. \n",
    "The vocabulary count of the movie reviews (10000) is used as the input shape. At the end we visualize the model summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 327
    },
    "colab_type": "code",
    "id": "_Pn83gBbxiK7",
    "outputId": "c297daca-b8a3-432a-a067-a2d145289ee9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_4 (Lambda)            (None, 256, 10000)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_mas (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                160016    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 160,033\n",
      "Trainable params: 160,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# put your code here\n",
    "model = Sequential()\n",
    "model.add(OneHot(VOCAB_SIZE,input_length=MAX_SEQUENCE_LENGTH))\n",
    "model.add(GlobalAveragePooling1DMasked())\n",
    "model.add(Dense(16,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Mz96xpCgvTj"
   },
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F3HbW_IKLqwT"
   },
   "source": [
    "To compile the model we need a loss function and an optimizer. We use binary_crossentropy loss function which is just a special case of categorical cross entropy. We also use Adam optimizer that can be used instead of the classical stochastic gradient descent procedure to update network weights iterative based in training data. You can read more about it here:\n",
    "(https://arxiv.org/abs/1412.6980v8\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qh1PWTNMxjUw"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E1jwQQqCN5Ia"
   },
   "source": [
    "When training, we want to check the accuracy of the model on data it hasn't seen before. So we create a validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f5lAqzQlxjSM"
   },
   "outputs": [],
   "source": [
    "X_val = np.array(X_train_enc[:10000])\n",
    "partial_X_train = np.array(X_train_enc[10000:])\n",
    "\n",
    "y_val = np.array(y_train[:10000])\n",
    "partial_y_train = np.array(y_train[10000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E8Kpo5G3OJEY"
   },
   "source": [
    "Then we start to train the model for 40 epochs in mini-batches of 512 samples and monitor the model's loss and accuracy on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "99_z39KAxjPi",
    "outputId": "a9e1e70b-1cc7-4c46-cf59-1a3ab9f5e274"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "15000/15000 [==============================] - 4s 251us/step - loss: 0.6926 - acc: 0.5543 - val_loss: 0.6920 - val_acc: 0.5720\n",
      "Epoch 2/40\n",
      "15000/15000 [==============================] - 3s 222us/step - loss: 0.6909 - acc: 0.6052 - val_loss: 0.6900 - val_acc: 0.6651\n",
      "Epoch 3/40\n",
      "15000/15000 [==============================] - 3s 223us/step - loss: 0.6888 - acc: 0.6694 - val_loss: 0.6879 - val_acc: 0.6486\n",
      "Epoch 4/40\n",
      "15000/15000 [==============================] - 3s 224us/step - loss: 0.6862 - acc: 0.6478 - val_loss: 0.6851 - val_acc: 0.6494\n",
      "Epoch 5/40\n",
      "15000/15000 [==============================] - 3s 225us/step - loss: 0.6832 - acc: 0.6701 - val_loss: 0.6820 - val_acc: 0.6755\n",
      "Epoch 6/40\n",
      "15000/15000 [==============================] - 3s 226us/step - loss: 0.6797 - acc: 0.6685 - val_loss: 0.6788 - val_acc: 0.6697\n",
      "Epoch 7/40\n",
      "15000/15000 [==============================] - 3s 228us/step - loss: 0.6758 - acc: 0.6808 - val_loss: 0.6748 - val_acc: 0.6675\n",
      "Epoch 8/40\n",
      "15000/15000 [==============================] - 3s 229us/step - loss: 0.6716 - acc: 0.6824 - val_loss: 0.6710 - val_acc: 0.6765\n",
      "Epoch 9/40\n",
      "15000/15000 [==============================] - 3s 229us/step - loss: 0.6671 - acc: 0.6863 - val_loss: 0.6665 - val_acc: 0.6810\n",
      "Epoch 10/40\n",
      "15000/15000 [==============================] - 3s 230us/step - loss: 0.6623 - acc: 0.6884 - val_loss: 0.6619 - val_acc: 0.6841\n",
      "Epoch 11/40\n",
      "15000/15000 [==============================] - 3s 231us/step - loss: 0.6573 - acc: 0.6894 - val_loss: 0.6571 - val_acc: 0.6823\n",
      "Epoch 12/40\n",
      "15000/15000 [==============================] - 3s 232us/step - loss: 0.6523 - acc: 0.6921 - val_loss: 0.6524 - val_acc: 0.6896\n",
      "Epoch 13/40\n",
      "15000/15000 [==============================] - 3s 229us/step - loss: 0.6472 - acc: 0.6929 - val_loss: 0.6477 - val_acc: 0.6901\n",
      "Epoch 14/40\n",
      "15000/15000 [==============================] - 3s 229us/step - loss: 0.6421 - acc: 0.6970 - val_loss: 0.6427 - val_acc: 0.6903\n",
      "Epoch 15/40\n",
      "15000/15000 [==============================] - 3s 229us/step - loss: 0.6369 - acc: 0.6977 - val_loss: 0.6379 - val_acc: 0.6913\n",
      "Epoch 16/40\n",
      "15000/15000 [==============================] - 3s 228us/step - loss: 0.6318 - acc: 0.6991 - val_loss: 0.6333 - val_acc: 0.6986\n",
      "Epoch 17/40\n",
      "15000/15000 [==============================] - 3s 227us/step - loss: 0.6267 - acc: 0.7033 - val_loss: 0.6286 - val_acc: 0.6996\n",
      "Epoch 18/40\n",
      "15000/15000 [==============================] - 3s 227us/step - loss: 0.6218 - acc: 0.7047 - val_loss: 0.6243 - val_acc: 0.7032\n",
      "Epoch 19/40\n",
      "15000/15000 [==============================] - 3s 226us/step - loss: 0.6167 - acc: 0.7068 - val_loss: 0.6191 - val_acc: 0.7009\n",
      "Epoch 20/40\n",
      "15000/15000 [==============================] - 3s 225us/step - loss: 0.6120 - acc: 0.7069 - val_loss: 0.6146 - val_acc: 0.6997\n",
      "Epoch 21/40\n",
      "15000/15000 [==============================] - 3s 224us/step - loss: 0.6072 - acc: 0.7121 - val_loss: 0.6103 - val_acc: 0.7089\n",
      "Epoch 22/40\n",
      "15000/15000 [==============================] - 3s 225us/step - loss: 0.6026 - acc: 0.7137 - val_loss: 0.6064 - val_acc: 0.7120\n",
      "Epoch 23/40\n",
      "15000/15000 [==============================] - 3s 224us/step - loss: 0.5982 - acc: 0.7171 - val_loss: 0.6017 - val_acc: 0.7127\n",
      "Epoch 24/40\n",
      "15000/15000 [==============================] - 3s 223us/step - loss: 0.5938 - acc: 0.7193 - val_loss: 0.5976 - val_acc: 0.7109\n",
      "Epoch 25/40\n",
      "15000/15000 [==============================] - 3s 224us/step - loss: 0.5894 - acc: 0.7209 - val_loss: 0.5953 - val_acc: 0.7140\n",
      "Epoch 26/40\n",
      "15000/15000 [==============================] - 3s 223us/step - loss: 0.5858 - acc: 0.7207 - val_loss: 0.5901 - val_acc: 0.7187\n",
      "Epoch 27/40\n",
      "15000/15000 [==============================] - 3s 224us/step - loss: 0.5818 - acc: 0.7249 - val_loss: 0.5877 - val_acc: 0.7180\n",
      "Epoch 28/40\n",
      "15000/15000 [==============================] - 3s 224us/step - loss: 0.5778 - acc: 0.7258 - val_loss: 0.5828 - val_acc: 0.7190\n",
      "Epoch 29/40\n",
      "15000/15000 [==============================] - 3s 224us/step - loss: 0.5743 - acc: 0.7291 - val_loss: 0.5794 - val_acc: 0.7246\n",
      "Epoch 30/40\n",
      "15000/15000 [==============================] - 3s 225us/step - loss: 0.5708 - acc: 0.7290 - val_loss: 0.5762 - val_acc: 0.7229\n",
      "Epoch 31/40\n",
      "15000/15000 [==============================] - 3s 225us/step - loss: 0.5676 - acc: 0.7313 - val_loss: 0.5733 - val_acc: 0.7222\n",
      "Epoch 32/40\n",
      "15000/15000 [==============================] - 3s 226us/step - loss: 0.5644 - acc: 0.7333 - val_loss: 0.5701 - val_acc: 0.7273\n",
      "Epoch 33/40\n",
      "15000/15000 [==============================] - 3s 226us/step - loss: 0.5612 - acc: 0.7338 - val_loss: 0.5671 - val_acc: 0.7284\n",
      "Epoch 34/40\n",
      "15000/15000 [==============================] - 3s 226us/step - loss: 0.5582 - acc: 0.7369 - val_loss: 0.5644 - val_acc: 0.7303\n",
      "Epoch 35/40\n",
      "15000/15000 [==============================] - 3s 226us/step - loss: 0.5555 - acc: 0.7377 - val_loss: 0.5618 - val_acc: 0.7306\n",
      "Epoch 36/40\n",
      "15000/15000 [==============================] - 3s 229us/step - loss: 0.5528 - acc: 0.7389 - val_loss: 0.5593 - val_acc: 0.7335\n",
      "Epoch 37/40\n",
      "15000/15000 [==============================] - 3s 228us/step - loss: 0.5501 - acc: 0.7404 - val_loss: 0.5574 - val_acc: 0.7340\n",
      "Epoch 38/40\n",
      "15000/15000 [==============================] - 3s 227us/step - loss: 0.5478 - acc: 0.7411 - val_loss: 0.5545 - val_acc: 0.7346\n",
      "Epoch 39/40\n",
      "15000/15000 [==============================] - 3s 227us/step - loss: 0.5455 - acc: 0.7426 - val_loss: 0.5524 - val_acc: 0.7372\n",
      "Epoch 40/40\n",
      "15000/15000 [==============================] - 3s 226us/step - loss: 0.5433 - acc: 0.7433 - val_loss: 0.5507 - val_acc: 0.7362\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=40,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i_9a_rybhG5J"
   },
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EYLH8kOgOo9W"
   },
   "source": [
    "To evaulate the model on test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "CFMt2Q7b3taP",
    "outputId": "c5443ca6-ab2e-4bb9-f573-34e73c618487"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 4s 153us/step\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test_enc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "9RrKiPHcAmQU",
    "outputId": "33bea862-cbfb-46da-d50b-31d4293dc324"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5500492589950562, 0.73816]\n"
     ]
    }
   ],
   "source": [
    "print(results)\n",
    "# loss, accuracay "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pW7IpHxMO6qp"
   },
   "source": [
    "Our first model accuracy using one-hot vectors is \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OwZk_yoWhPJB"
   },
   "source": [
    "### Plotting the accuracy graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JIDPH1J7PMzN"
   },
   "source": [
    "To plot a graph of accuracy and loss over time we can use Matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "LS9k2vvSAqB7",
    "outputId": "614e07d0-e840-45d4-ce19-581f7844cdb8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAocxxpi4WOAwxhgTl/8PDKGwbfrAB7EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "\n",
    "acc = history_dict['acc']\n",
    "val_acc = history_dict['val_acc']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "8QCewvf_1yD0",
    "outputId": "48708c46-5f79-447a-9b03-a66e2b4ac1bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a7OwOQw4h8RX"
   },
   "source": [
    "### Neural Network model using word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l-QzOMO_P4jc"
   },
   "source": [
    "Now instead of one-hot vectors, we want to use embedding. We change our first layer in model1 to an Embedding layer. This layer takes the integer-encoded vocabulary and looks up the embedding vector for each word-index. These vectors are learned as the model trains. The vectors add a dimension to the output array. The resulting dimensions are: (batch, sequence, embedding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "MFrCsL-NBFVL",
    "outputId": "5863b38e-f1f9-410d-ce95-bd8bbfaef3bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "15000/15000 [==============================] - 1s 38us/step - loss: 0.6921 - acc: 0.5464 - val_loss: 0.6902 - val_acc: 0.6077\n",
      "Epoch 2/40\n",
      "15000/15000 [==============================] - 0s 12us/step - loss: 0.6862 - acc: 0.6616 - val_loss: 0.6817 - val_acc: 0.6790\n",
      "Epoch 3/40\n",
      "15000/15000 [==============================] - 0s 12us/step - loss: 0.6733 - acc: 0.7391 - val_loss: 0.6654 - val_acc: 0.7475\n",
      "Epoch 4/40\n",
      "15000/15000 [==============================] - 0s 13us/step - loss: 0.6499 - acc: 0.7673 - val_loss: 0.6385 - val_acc: 0.7716\n",
      "Epoch 5/40\n",
      "15000/15000 [==============================] - 0s 13us/step - loss: 0.6151 - acc: 0.7921 - val_loss: 0.6020 - val_acc: 0.7892\n",
      "Epoch 6/40\n",
      "15000/15000 [==============================] - 0s 12us/step - loss: 0.5711 - acc: 0.8153 - val_loss: 0.5587 - val_acc: 0.7950\n",
      "Epoch 7/40\n",
      "15000/15000 [==============================] - 0s 13us/step - loss: 0.5230 - acc: 0.8319 - val_loss: 0.5145 - val_acc: 0.8221\n",
      "Epoch 8/40\n",
      "15000/15000 [==============================] - 0s 12us/step - loss: 0.4749 - acc: 0.8499 - val_loss: 0.4726 - val_acc: 0.8360\n",
      "Epoch 9/40\n",
      "15000/15000 [==============================] - 0s 12us/step - loss: 0.4305 - acc: 0.8646 - val_loss: 0.4361 - val_acc: 0.8466\n",
      "Epoch 10/40\n",
      "15000/15000 [==============================] - 0s 13us/step - loss: 0.3916 - acc: 0.8749 - val_loss: 0.4055 - val_acc: 0.8540\n",
      "Epoch 11/40\n",
      "15000/15000 [==============================] - 0s 12us/step - loss: 0.3586 - acc: 0.8848 - val_loss: 0.3807 - val_acc: 0.8612\n",
      "Epoch 12/40\n",
      "15000/15000 [==============================] - 0s 11us/step - loss: 0.3316 - acc: 0.8915 - val_loss: 0.3611 - val_acc: 0.8647\n",
      "Epoch 13/40\n",
      "15000/15000 [==============================] - 0s 12us/step - loss: 0.3087 - acc: 0.8962 - val_loss: 0.3465 - val_acc: 0.8663\n",
      "Epoch 14/40\n",
      "15000/15000 [==============================] - 0s 12us/step - loss: 0.2882 - acc: 0.9027 - val_loss: 0.3328 - val_acc: 0.8738\n",
      "Epoch 15/40\n",
      "15000/15000 [==============================] - 0s 13us/step - loss: 0.2707 - acc: 0.9076 - val_loss: 0.3225 - val_acc: 0.8753\n",
      "Epoch 16/40\n",
      "15000/15000 [==============================] - 0s 11us/step - loss: 0.2555 - acc: 0.9109 - val_loss: 0.3151 - val_acc: 0.8766\n",
      "Epoch 17/40\n",
      "15000/15000 [==============================] - 0s 11us/step - loss: 0.2413 - acc: 0.9170 - val_loss: 0.3073 - val_acc: 0.8792\n",
      "Epoch 18/40\n",
      "15000/15000 [==============================] - 0s 12us/step - loss: 0.2290 - acc: 0.9208 - val_loss: 0.3014 - val_acc: 0.8813\n",
      "Epoch 19/40\n",
      "15000/15000 [==============================] - 0s 12us/step - loss: 0.2178 - acc: 0.9253 - val_loss: 0.2970 - val_acc: 0.8821\n",
      "Epoch 20/40\n",
      "15000/15000 [==============================] - 0s 11us/step - loss: 0.2071 - acc: 0.9291 - val_loss: 0.2930 - val_acc: 0.8820\n",
      "Epoch 21/40\n",
      "15000/15000 [==============================] - 0s 12us/step - loss: 0.1974 - acc: 0.9335 - val_loss: 0.2902 - val_acc: 0.8838\n",
      "Epoch 22/40\n",
      "15000/15000 [==============================] - 0s 12us/step - loss: 0.1881 - acc: 0.9373 - val_loss: 0.2881 - val_acc: 0.8842\n",
      "Epoch 23/40\n",
      "15000/15000 [==============================] - 0s 11us/step - loss: 0.1798 - acc: 0.9415 - val_loss: 0.2864 - val_acc: 0.8844\n",
      "Epoch 24/40\n",
      "15000/15000 [==============================] - 0s 13us/step - loss: 0.1721 - acc: 0.9439 - val_loss: 0.2858 - val_acc: 0.8851\n",
      "Epoch 25/40\n",
      "15000/15000 [==============================] - 0s 13us/step - loss: 0.1646 - acc: 0.9480 - val_loss: 0.2849 - val_acc: 0.8845\n",
      "Epoch 26/40\n",
      "15000/15000 [==============================] - 0s 11us/step - loss: 0.1575 - acc: 0.9507 - val_loss: 0.2845 - val_acc: 0.8846\n",
      "Epoch 27/40\n",
      "15000/15000 [==============================] - 0s 12us/step - loss: 0.1511 - acc: 0.9533 - val_loss: 0.2849 - val_acc: 0.8847\n",
      "Epoch 28/40\n",
      "15000/15000 [==============================] - 0s 13us/step - loss: 0.1447 - acc: 0.9553 - val_loss: 0.2852 - val_acc: 0.8847\n",
      "Epoch 29/40\n",
      "15000/15000 [==============================] - 0s 13us/step - loss: 0.1392 - acc: 0.9590 - val_loss: 0.2866 - val_acc: 0.8861\n",
      "Epoch 30/40\n",
      "15000/15000 [==============================] - 0s 13us/step - loss: 0.1337 - acc: 0.9604 - val_loss: 0.2876 - val_acc: 0.8852\n",
      "Epoch 31/40\n",
      "15000/15000 [==============================] - 0s 13us/step - loss: 0.1280 - acc: 0.9630 - val_loss: 0.2910 - val_acc: 0.8844\n",
      "Epoch 32/40\n",
      "15000/15000 [==============================] - 0s 13us/step - loss: 0.1230 - acc: 0.9655 - val_loss: 0.2910 - val_acc: 0.8863\n",
      "Epoch 33/40\n",
      "15000/15000 [==============================] - 0s 13us/step - loss: 0.1184 - acc: 0.9664 - val_loss: 0.2926 - val_acc: 0.8848\n",
      "Epoch 34/40\n",
      "15000/15000 [==============================] - 0s 12us/step - loss: 0.1150 - acc: 0.9677 - val_loss: 0.2954 - val_acc: 0.8844\n",
      "Epoch 35/40\n",
      "15000/15000 [==============================] - 0s 14us/step - loss: 0.1096 - acc: 0.9702 - val_loss: 0.2981 - val_acc: 0.8841\n",
      "Epoch 36/40\n",
      "15000/15000 [==============================] - 0s 13us/step - loss: 0.1051 - acc: 0.9719 - val_loss: 0.3006 - val_acc: 0.8839\n",
      "Epoch 37/40\n",
      "15000/15000 [==============================] - 0s 13us/step - loss: 0.1015 - acc: 0.9739 - val_loss: 0.3034 - val_acc: 0.8841\n",
      "Epoch 38/40\n",
      "15000/15000 [==============================] - 0s 12us/step - loss: 0.0972 - acc: 0.9752 - val_loss: 0.3072 - val_acc: 0.8828\n",
      "Epoch 39/40\n",
      "15000/15000 [==============================] - 0s 14us/step - loss: 0.0936 - acc: 0.9766 - val_loss: 0.3092 - val_acc: 0.8827\n",
      "Epoch 40/40\n",
      "15000/15000 [==============================] - 0s 15us/step - loss: 0.0901 - acc: 0.9779 - val_loss: 0.3135 - val_acc: 0.8822\n",
      "25000/25000 [==============================] - 1s 41us/step\n",
      "[0.3335925381374359, 0.87232]\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE= 10000\n",
    "model2 = Sequential()\n",
    "model2.add(Embedding(VOCAB_SIZE,16,input_length=MAX_SEQUENCE_LENGTH))\n",
    "model2.add(GlobalAveragePooling1DMasked())\n",
    "model2.add(Dense(16,activation='relu'))\n",
    "model2.add(Dense(1,activation='sigmoid'))\n",
    "# put the code here\n",
    "\n",
    "model2.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "X_val = np.array(X_train_enc[:10000])\n",
    "partial_X_train = np.array(X_train_enc[10000:])\n",
    "\n",
    "history2 = model2.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=40,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)\n",
    "\n",
    "results = model2.evaluate(X_test_enc, y_test)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "I4zIPJDcTPq3",
    "outputId": "82531398-bdbf-42a3-ab74-cdc4dcd79095"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 1s 42us/step\n"
     ]
    }
   ],
   "source": [
    "results = model2.evaluate(X_test_enc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "waS96edDTRyL",
    "outputId": "9098cb45-1f8c-45b5-c15d-7c197c3e5534"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3335925381374359, 0.87232]\n"
     ]
    }
   ],
   "source": [
    "print (results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "XB7aveVzTC5a",
    "outputId": "f6670546-5db6-4e80-c719-f8025c9cf965"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deZwU9Z3/8deH4T4UBTwCyCAayXDD\niBrwiNGI90bNKuIvIcYQ3GCMJnFNcJWYqJsY45G42eBuEg+UZc1qSKIx8QSPRAYVIp6EQwc5hgG5\nBmWAz++Pb/XQM3T3NDPTUz3d7+fjUY+uq6s/XT1Tn6rv91vfMndHRESKV7u4AxARkXgpEYiIFDkl\nAhGRIqdEICJS5JQIRESKnBKBiEiRUyKQvZhZiZltNbPDWnLdOJnZEWbW4m2lzewUM1uRNP22mR2f\nzbpN+Kz/MrPvNfX9Ium0jzsAaT4z25o02RX4GNgVTX/N3Wfty/bcfRfQvaXXLQbuflRLbMfMLgMu\ncfeTkrZ9WUtsW6QhJYIC4O51B+LojPMyd38y3fpm1t7dd7ZGbCKN0d9j/FQ0VATM7Idm9j9m9pCZ\nbQEuMbPjzOyvZvahma02s7vMrEO0fnszczMrjaYfiJY/bmZbzOwlMxu4r+tGy083s3fMbJOZ/czM\nXjCzyWnizibGr5nZUjPbaGZ3Jb23xMxuN7NqM1sGTMiwf6ab2ewG8+42s59G45eZ2ZvR9/lHdLae\nbluVZnZSNN7VzO6PYlsCjGmw7nVmtiza7hIzOyeaPwz4OXB8VOy2Pmnfzkh6/9Tou1eb2aNmdmg2\n+2Zf9nMiHjN70sw2mNkaM7sm6XP+Ldonm82swsw+kaoYzsyeT/zO0f6cF33OBuA6MzvSzJ6JPmN9\ntN/2T3r/gOg7VkXL7zSzzlHMn0pa71AzqzGzXum+r6Tg7hoKaABWAKc0mPdDYAdwNiH5dwGOBo4h\nXBUeDrwDTIvWbw84UBpNPwCsB8qBDsD/AA80Yd2DgC3AudGyq4FaYHKa75JNjL8D9gdKgQ2J7w5M\nA5YA/YBewLzw557ycw4HtgLdkra9DiiPps+O1jHgZGA7MDxadgqwImlblcBJ0fhPgGeBA4ABwBsN\n1v1n4NDoN7k4iuHgaNllwLMN4nwAmBGNfy6KcSTQGfgP4Ols9s0+7uf9gbXAlUAnYD9gbLTsu8Ai\n4MjoO4wEDgSOaLivgecTv3P03XYClwMlhL/HTwKfBTpGfycvAD9J+j6vR/uzW7T+uGjZTOCmpM/5\nFvBI3P+HbW2IPQANLfyDpk8ETzfyvm8D/xuNpzq4/2fSuucArzdh3UuB+UnLDFhNmkSQZYzHJi3/\nP+Db0fg8QhFZYtkZDQ9ODbb9V+DiaPx04O0M6/4B+Ho0nikRvJf8WwD/krxuiu2+DpwZjTeWCO4F\nbk5ath+hXqhfY/tmH/fz/wMWpFnvH4l4G8zPJhEsaySGCxKfCxwPrAFKUqw3DlgOWDT9GnBeS/9f\nFfqgoqHi8X7yhJkNNrM/Rpf6m4Ebgd4Z3r8mabyGzBXE6db9RHIcHv5zK9NtJMsYs/osYGWGeAEe\nBCZG4xdH04k4zjKzv0XFFh8SzsYz7auEQzPFYGaTzWxRVLzxITA4y+1C+H5123P3zcBGoG/SOln9\nZo3s5/6EA34qmZY1puHf4yFmNsfMVkUx/KZBDCs8NEyox91fIFxdjDezocBhwB+bGFPRUiIoHg2b\nTv6ScAZ6hLvvB1xPOEPPpdWEM1YAzMyof+BqqDkxriYcQBIaa946BzjFzPoSiq4ejGLsAjwM3EIo\ntukJ/DnLONaki8HMDgd+QSge6RVt962k7TbW1PUDQnFTYns9CEVQq7KIq6FM+/l9YFCa96Vbti2K\nqWvSvEMarNPw+/2I0NptWBTD5AYxDDCzkjRx3AdcQrh6mePuH6dZT9JQIihePYBNwLaosu1rrfCZ\nfwBGm9nZZtaeUO7cJ0cxzgG+aWZ9o4rDf820sruvIRRf/IZQLPRutKgTody6CthlZmcRyrKzjeF7\nZtbTwn0W05KWdSccDKsIOfGrhCuChLVAv+RK2wYeAr5iZsPNrBMhUc1397RXWBlk2s9zgcPMbJqZ\ndTKz/cxsbLTsv4AfmtkgC0aa2YGEBLiG0CihxMymkJS0MsSwDdhkZv0JxVMJLwHVwM0WKuC7mNm4\npOX3E4qSLiYkBdlHSgTF61vAlwiVt78kVOrmlLuvBS4Efkr4xx4EvEo4E2zpGH8BPAX8HVhAOKtv\nzIOEMv+6YiF3/xC4CniEUOF6ASGhZeMGwpXJCuBxkg5S7r4Y+BnwcrTOUcDfkt77F+BdYK2ZJRfx\nJN7/J0IRziPR+w8DJmUZV0Np97O7bwJOBc4nJKd3gBOjxbcCjxL282ZCxW3nqMjvq8D3CA0Hjmjw\n3VK5ARhLSEhzgd8mxbATOAv4FOHq4D3C75BYvoLwO3/s7i/u43cX9lSwiLS66FL/A+ACd58fdzzS\ndpnZfYQK6Blxx9IW6YYyaVVmNoHQQmc7oflhLeGsWKRJovqWc4FhccfSVqloSFrbeGAZoWz8NODz\nqtyTpjKzWwj3Mtzs7u/FHU9bpaIhEZEipysCEZEi1+bqCHr37u2lpaVxhyEi0qYsXLhwvbunbK7d\n5hJBaWkpFRUVcYchItKmmFnau+tVNCQiUuSUCEREipwSgYhIkWtzdQSp1NbWUllZyUcffRR3KJJB\n586d6devHx06pOs+R0TiUBCJoLKykh49elBaWkro0FLyjbtTXV1NZWUlAwcObPwNItJqCqJo6KOP\nPqJXr15KAnnMzOjVq5eu2kSaYNYsKC2Fdu3C66xZLbv9gkgEgJJAG6DfSIpVYwfyTMtnzYIpU2Dl\nSnAPr1OmtGwyKJhEICISl+YcyBtbPn061NTU/7yamjC/pSgRtIDq6mpGjhzJyJEjOeSQQ+jbt2/d\n9I4dO7Laxpe//GXefvvtjOvcfffdzGrpa0IRaVRzDvSNHcgbW/5emq700s1vkrgfmryvw5gxY7yh\nN954Y695mTzwgPuAAe5m4fWBB/bp7RndcMMNfuutt+41f/fu3b5r166W+6A2al9/K5HWku648MAD\n7l27uofDfBi6dt2zfMCA+ssSw4ABYblZ6uVm2S1vbPvZAipcD68PWqO8LWHp0qWUlZUxadIkhgwZ\nwurVq5kyZQrl5eUMGTKEG2+8sW7d8ePH89prr7Fz50569uzJtddey4gRIzjuuONYt24dANdddx13\n3HFH3frXXnstY8eO5aijjuLFF8ODmbZt28b5559PWVkZF1xwAeXl5bz22mt7xXbDDTdw9NFHM3To\nUKZOnYpHvdC+8847nHzyyYwYMYLRo0ezYsUKAG6++WaGDRvGiBEjmN6S16QiLSRX5fDNPWM/LM3T\nshPzG1t+003QtWv9ZV27hvktJl2GyNehuVcELZVd00m+Inj33XfdzHzBggV1y6urq93dvba21seP\nH+9Llixxd/dx48b5q6++6rW1tQ74Y4895u7uV111ld9yyy3u7j59+nS//fbb69a/5ppr3N39d7/7\nnZ922mnu7n7LLbf4v/zLv7i7+2uvvebt2rXzV199da84E3Hs3r3bL7roorrPGz16tM+dO9fd3bdv\n3+7btm3zuXPn+vjx472mpqbee5tCVwTSVJmu5Bs7a2/OWX1zz9ibG1tj3z1b6Ipgj1Ypb0syaNAg\nysvL66YfeughRo8ezejRo3nzzTd544039npPly5dOP300wEYM2ZM3Vl5Q+edd95e6zz//PNcdNFF\nAIwYMYIhQ4akfO9TTz3F2LFjGTFiBM899xxLlixh48aNrF+/nrPPPhsIN4B17dqVJ598kksvvZQu\nXboAcOCBB+77jhBpRL6Wwzf3jH3SJJg5EwYMALPwOnNmmJ/N8sQ6K1bA7t3hdVJTn06dRtElgsZ+\n1JbWrVu3uvF3332XO++8k6effprFixczYcKElO3qO3bsWDdeUlLCzp07U267U6dOja6TSk1NDdOm\nTeORRx5h8eLFXHrppWrfL60i3cG+uQf6xk7wmlN809wDfWKdTAfyXB/oG1N0iaBVytvS2Lx5Mz16\n9GC//fZj9erVPPHEEy3+GePGjWPOnDkA/P3vf095xbF9+3batWtH79692bJlC7/97W8BOOCAA+jT\npw+///3vgXCjXk1NDaeeeiq/+tWv2L59OwAbNmxo8bilMBRiOXw+nLHnWtElgmx+1FwZPXo0ZWVl\nDB48mC9+8YuMGzeuxT/jiiuuYNWqVZSVlfH973+fsrIy9t9//3rr9OrViy996UuUlZVx+umnc8wx\nx9QtmzVrFrfddhvDhw9n/PjxVFVVcdZZZzFhwgTKy8sZOXIkt99+e4vHLW1fc87qm3ugb+wEryWK\nb9rygb5R6SoP8nVoieajhay2tta3b9/u7u7vvPOOl5aWem1tbcxR7aHfKr81VimZaXlzmlE2t8K1\nubEXAzJUFsd+YN/XQYkgs40bN/ro0aN9+PDhPmzYMH/iiSfiDqke/Vb5q7mtW5rTuqa1Ws4UMyUC\nyRv6reLVnDP65i7PJtHoQJ87mRJB0dURiBS6prbMaW7LG5XDt11KBCIFpDktc5rb8qYYWtcUKiUC\nkTYmUxPN5rTMaW7LG9CBvq1SIhDJM825w7Y5d8i2xB2w0kalqzzI1yEfK4tPOukk/9Of/lRv3u23\n3+5Tp07N+L5u3bq5u/uqVav8/PPPT7nOiSeeWK+volRuv/1237ZtW9306aef7hs3bswm9FYX92+V\n75rb02VzW+ZI4UKVxbk1ceJEZs+eXW/e7NmzmThxYlbv/8QnPsHDDz/c5M+/4447qEkqD3jsscfo\n2bNnk7cnudXUoh1oXvGOzuglrXQZIl+HfLwiqK6u9j59+vjHH3/s7u7Lly/3/v37++7du33Lli1+\n8skn+6hRo3zo0KH+6KOP1r0vcUWwfPlyHzJkiLu719TU+IUXXuiDBw/2f/qnf/KxY8fWXRFMnTrV\nx4wZ42VlZX799de7u/udd97pHTp08KFDh/pJJ53k7u4DBgzwqqoqd3e/7bbbfMiQIT5kyJC6nkuX\nL1/ugwcP9ssuu8zLysr81FNPretZNNncuXN97NixPnLkSP/sZz/ra9ascXf3LVu2+OTJk33o0KE+\nbNgwf/jhh93d/fHHH/dRo0b58OHD/eSTT065r+L+reKWy7b4yZ+hZpjSEMV0H8GVV7qfeGLLDlde\n2fhOPvPMM+sO8rfccot/61vfcvdwp++mTZvc3b2qqsoHDRrku3fvdvfUieC2227zL3/5y+7uvmjR\nIi8pKalLBInun3fu3OknnniiL1q0yN3rH/iTpysqKnzo0KG+detW37Jli5eVlfkrr7ziy5cv95KS\nkrruqb/whS/4/fffv9d32rBhQ12s99xzj1999dXu7n7NNdf4lUk7ZcOGDb5u3Trv16+fL1u2rF6s\nDRVDIshlW30V70hTZUoEKhpqIcnFQ8nFQu7O9773PYYPH84pp5zCqlWrWLt2bdrtzJs3j0suuQSA\n4cOHM3z48Lplc+bMYfTo0YwaNYolS5ak7FAu2fPPP8/nP/95unXrRvfu3TnvvPOYP38+AAMHDmTk\nyJFA+q6uKysrOe200xg2bBi33norS5YsAeDJJ5/k61//et16BxxwAH/961854YQTGDhwIFC8XVU3\nt61+S/R0KbKv2scdQEuLHuDV6s4991yuuuoqXnnlFWpqahgzZgwQOnGrqqpi4cKFdOjQgdLS0iZ1\n+bx8+XJ+8pOfsGDBAg444AAmT57crK6jE11YQ+jGOtGzaLIrrriCq6++mnPOOYdnn32WGTNmNPnz\nCk2iXX6iNU6iDD5TGf+kSWHdlSv33l5yyx1Ive2ESZN04JeWpSuCFtK9e3c+85nPcOmll9arJN60\naRMHHXQQHTp04JlnnmFlqqNAkhNOOIEHH3wQgNdff53FixcDoQvrbt26sf/++7N27Voef/zxuvf0\n6NGDLVu27LWt448/nkcffZSamhq2bdvGI488wvHHH5/1d9q0aRN9+/YF4N57762bf+qpp3L33XfX\nTW/cuJFjjz2WefPmsXz5cqDtd1Xd1CaczT3jB7XFl9anRNCCJk6cyKJFi+olgkmTJlFRUcGwYcO4\n7777GDx4cMZtXH755WzdupVPfepTXH/99XVXFiNGjGDUqFEMHjyYiy++uF4X1lOmTGHChAl85jOf\nqbet0aNHM3nyZMaOHcsxxxzDZZddxqhRo7L+PjNmzOALX/gCY8aMoXfv3nXzr7vuOjZu3MjQoUMZ\nMWIEzzzzDH369GHmzJmcd955jBgxggsvvDDrz8k3zelOuSXuvhVpdekqD/J1yMdWQ5K9fPmtctWd\nsipzJV+hymKRPZpboZvprF9n/NIWKRFIQWrOTVst8bBylfFLW1IwiSBc+Ug+a63fSE04RfZNQSSC\nzp07U11drWSQx9yd6upqOnfunPPPau4Zv7pTlmJjbe3gWV5e7hUVFfXm1dbWUllZ2ax29ZJ7nTt3\npl+/fnTo0KHZ20rXjh9CcVCqP2uzcOBOXDEkJ4uuXXVWL4XNzBa6e3mqZQVxQ1mHDh3q7miVwpHu\nYN/wQJ4o+oGWu2lLpJgUxBWBFJ5MZ+3Tp6c+0A8YEIppdMYvsrdMVwQFUUcghac5T9pSZa7IvlEi\nkNhkauLZnCdtgSpzRfZFThOBmU0ws7fNbKmZXZti+QAze8rMFpvZs2bWL5fxSP5orIlnpoN9Nv31\niEj2cpYIzKwEuBs4HSgDJppZWYPVfgLc5+7DgRuBW3IVj+SXxpp46klbIq0nl1cEY4Gl7r7M3XcA\ns4FzG6xTBjwdjT+TYrm0YU0t+oHsHqSuoh+RlpHLRNAXeD9pujKal2wRcF40/nmgh5n1arghM5ti\nZhVmVlFVVZWTYKVlNafoJ0EHe5HWEXdl8beBE83sVeBEYBWwq+FK7j7T3cvdvbxPnz6tHaOk0Zz+\nfFTOL5I/cnlD2Sqgf9J0v2heHXf/gOiKwMy6A+e7+4c5jElaSGM3dWVT9AO6qUskH+TshjIzaw+8\nA3yWkAAWABe7+5KkdXoDG9x9t5ndBOxy9+szbVc3lOWH0tLMN3U1tlxEWlcsN5S5+05gGvAE8CYw\nx92XmNmNZnZOtNpJwNtm9g5wMKCCgTzSnMpeFf2ItB057WvI3R8DHmsw7/qk8YeBh3MZgzSN+vPJ\nb4kLebN449i+Haqq6g/r14eTh/32gx496r8mxrt3h/ZZHH1qaqCyMgzvvx9et2yBPn3goIPg4IP3\nvPbpk902ZW/qa0hSaqxoR/357K22FtasgVWrwgFr3Tr4+GPYsWPvobY2vO7alX7YsQO2bQtDTU39\n8ZoaKCmBLl1SD5077+lt1T3za6p5mbiHOKqqwmtTde4cEkLDoX17WL06HPg3bNj7fR06hP2XSq9e\n0LMndOyYfujQIQzt26d+LSkJiaykJPWQ6Tdr3x4OPBB69w6xJL/27BneH5eC731UWl4hV/a6w9q1\nIdGtXw9bt6Yfdu0KB4V27cKBNfl19+6wnVWrwrB2berur5N16lT/gJTuYFNSEtbt1i2c6XbrFhJt\n165hvEuX8Pnbt6cfzPbEmji4NfwOideG8xq70ujaNcSVGHr3rj/uHs7cN2+u/5oYz7TPd+wIf0+f\n/jT07w/9+u157ds3JJDNm8P+Xrduz2tifPPm1Mm3pmZPEq6thZ07678mhl27wr5NHNwbk/ybJbaV\nilnYb+n2ebt24W+iU6fwHVO9Tp0KEyY0HtO+UiIocum6em6s6AfCevl64P/wQ3j7bVi6NHyPFSv2\nvL73HmR6dEXHjuHMtFu38M+d7gwaQrFE374wcmR4TR4OPjgcsBMH/pKS+ItyWlOvve4Iajn77x+G\nT34yd5+RkJwUdu+uf7XQrkEtq3tIZtXV4SSj4eu2bZmvzGprw1XkRx/Vf62uDq9btuTmOyoRFLFM\n9QA33ZS66CdfKnsTZ5xr1oQDfsNh3br66/fpE4q1hg+Hc84J46WlYX6izLpHj3Dw79gxlq8keSpx\n9p7N85TMwt9Rjx7h76utUCIoYplu+ko08Wytop/du0N5cKrL/fXr9wzJZ1gNL8F794ajjoKzzgqv\nRx0FRx4ZDvrduuUmbpFCoMriItbYIx1zaccOePhh+M//hHffDRWPqcpjS0pCEUPDirfE60EHhYP9\nUUeFSjoRSU2VxZJSNvUALa26OrQs+vnP4YMPQhnvWWftaQKY3BzwoIPCwb1hOayItCwlggKX6SHv\nrVkP8NZbcMcdcN99oUXLqafCPfeEFhA60IvES4mggDV2U1gumoC6h7L+NWv2tKmfPRsefzw0f7vk\nEvjmN2Ho0OZ9NxFpOaojKGC56u/HHZYtgwULoKIitNJJHPjXrt27Evfgg+HrX4evfS0U94hI61Md\nQZFq7KawbFVWhoN+4sBfUQEbN4ZlnTrB4MFw6KHhLP+QQ/YeBg5Uk0yRfKZEUMCaUxm8Ywf89reh\nUvfFF8O8khIYNgwuuADKy+Hoo8PBP5v21SKSv5QIClhTKoM/+AB++cswrF0LRxwBP/oRnHACjBgR\n7pQVkcKiRFDAsq0Mdofnnw9n///3f6E9/xlnwLRp8LnPqVWPSKHTv3gbl+mZAZD5ub8ffQS/+hWM\nGhXO+P/8Z7jyynCD1x/+oKadIsVCVwRtWGPNQ9P54AP4j/8IxT/r14dy/kT30Q0fJiMihU/ne21Y\nYw+Ib+jll8PBfsAAuPnm0M3v00/D4sXw1a8qCYgUK10RtGHZNA91D+X+t90GL70UekWcNi0Mgwa1\nTpwikt+UCNqwxpqHvvMOXH55OOs/4gi46y6YPDkkAxGRBBUNtWHpHhA/YwZ8//uhzf/ChaGHz7ff\nhiuuUBIQkb3piqANS9U8dNIkuOWWcDUwcSL89Kfh7l4RkXR0RdDGJZqHrl0LJ54YKoF37oQnnoAH\nH1QSEJHGKRHkucbuEwC4//7Q389DD4Wrg9dfDzeCiYhkQ0VDeayx+wRqa+Hqq8MdwePGhXsBysri\ni1dE2iZdEeSxTPcJVFfDaaeFJHD11fDss0oCItI0uiLIY+nuE1i5MvT8+cEHcO+98MUvtm5cIlJY\nlAjyWLr7BMxCP0HPPQfHHNP6cYlIYVHRUB5LdZ8AwOGHh4fDKAmISEtQIshjkyaFCuD+/ffMGz8+\ntAr6xCfii0tECosSQZ67+GIYOTI0H73tNpg3Dzp3jjsqESkkSgQxa+w+gYcfht//Hm69NbQOMosj\nShEpZKosjlFj9wl8+CF84xswenR4FRHJBV0RxKix5wl897uwbh3ccw+0V8oWkRxRIohRpucJvPhi\n6DX0yivDFYGISK4oEcQo8dyAhvr3D0VE/fvDjTe2bkwiUnyUCGKU7nkCxxwDS5bA3XdD9+7xxCYi\nxUOJIEaJ+wQGDAitgQYMCFcAc+fC+efD2WfHHaGIFINGE4GZXWFmBzRl42Y2wczeNrOlZnZtiuWH\nmdkzZvaqmS02szOa8jltWeJ5Art3w/Ll8Pjj0KlTeKykiEhryOaK4GBggZnNiQ7sWbVkN7MS4G7g\ndKAMmGhmDfvHvA6Y4+6jgIuA/8g+9MLzwAPw1FPhCWO6c1hEWkujicDdrwOOBP4bmAy8a2Y3m9mg\nRt46Fljq7svcfQcwGzi34eaB/aLx/YEP9iH2glJdHW4YO/ZYmDo17mhEpJhkVUfg7g6siYadwAHA\nw2b24wxv6wu8nzRdGc1LNgO4xMwqgceAK1JtyMymmFmFmVVUVVVlE3JeyeYpY9/5TriBbObMsJ6I\nSGvJpo7gSjNbCPwYeAEY5u6XA2OA85v5+ROB37h7P+AM4H4z2ysmd5/p7uXuXt6nT59mfmTrStw9\nvHIluO+5eziRDN56C667Dn79a/j2t2HYsHjjFZHik839qgcC57l7vZ7x3X23mZ2V4X2rgKR+M+kX\nzUv2FWBCtL2XzKwz0BtYl0VcbUK6u4enTYMf/xgWLw4ths44A/7t3+KJUUSKWzaFEI8DGxITZraf\nmR0D4O5vZnjfAuBIMxtoZh0JlcFzG6zzHvDZaLufAjoDba/sJ4N0dw9/+GG4R+DOO6GyEv74x9TP\nHhARybVsrgh+ASR3crA1xby9uPtOM5sGPAGUAL9y9yVmdiNQ4e5zgW8B95jZVYSK48lRfUTBSPeU\nsb594YUXWj8eEZGGskkElnxwjoqEsuoCzd0fI1QCJ8+7Pmn8DWBclrG2SWedFe4QTta1K/zoR/HE\nIyLSUDZFQ8vM7Btm1iEargSW5TqwQvDII6HjuMGDQ79BibuHZ84MN5KJiOSDbM7spwJ3EW7+cuAp\nYEougyoEf/wjXHghjB0LTzwBPXrEHZGISGqNJgJ3X0eo6JUsPflk6Cto+PDQZYSSgIjks0YTQdSk\n8yvAEEKrHgDc/dIcxtVmzZsH55wDRx0VrgT23z/uiEREMsumjuB+4BDgNOA5wv0AW3IZVFv10ktw\n5pnh7uG//AV69Yo7IhGRxmWTCI5w938Dtrn7vcCZwDG5DavtWbgQJkyAQw4JHccddFDcEYmIZCeb\nRFAbvX5oZkMJncPpMJfkrrtCpfDmzbB9Ozz9dNwRiYhkL5tWQzOj5xFcR7gzuDugzhAi998PV10V\nnicAsGpV6EsI1ERURNqGjFcEUQdwm919o7vPc/fD3f0gd/9lK8WX977xjT1JIKGmJvQxJCLSFmRM\nBO6+G7imlWJpc159NfQZlEq6PoZERPJNNnUET5rZt82sv5kdmBhyHlmeq6kJRT8lJamXH3ZY68Yj\nItJU2SSCC4GvA/OAhdFQkcug2oJrroE33wzPEGjYa2jXrnDTTfHEJSKyr7K5s3hgawTSljz2WOhI\n7qqr4N//PTxMZvr0UBx02GEhCaiiWETaCmus12cz+2Kq+e5+X04iakR5eblXVMR3QbJuXTjwH3ww\nvPwydO7c+HtEROJmZgvdvTzVsmyajx6dNN6Z8CCZV4BYEkGc3OErX4FNm8JNY0oCIlIIsikaqvdA\neTPrCczOWUR57Je/hD/8Ae64A4YOjTsaEZGWkU1lcUPbgKKrN3jrLbj6avjc5+CKKxpfX0Skrcim\n99HfE55DACFxlAFzchlUPqZmyCIAAA5USURBVJo6NbQG+s1voF1T0qeISJ7Kpo7gJ0njO4GV7l6Z\no3jy0saNoXvpG26AQw+NOxoRkZaVzbnte8Df3P05d38BqDaz0pxGlWd+8INQUTxjRuhietasuCMS\nEWk52SSC/wWSe9PZFc0rCrNmwc9+tmd65crQqZySgYgUimwSQXt335GYiMY75i6k/DJ9OuzcWX+e\nOpUTkUKSTSKoMrNzEhNmdi6wPnch5ZeVK1PPV6dyIlIosqksngrMMrOfR9OVQMq7jQtRnz5QVbX3\nfHUqJyKFIpsbyv4BHGtm3aPprTmPKo8cfXToWyiZOpUTkULSaNGQmd1sZj3dfau7bzWzA8zsh60R\nXD5Ytw4GD4YBA8AsvM6cqU7lRKRwZFNHcLq71z1+xd03AmfkLqT8sWkTvPIK/PM/w4oV4UlkK1Yo\nCYhIYckmEZSYWafEhJl1ATplWL9gPP98OPifdFLckYiI5E42lcWzgKfM7NeAAZOBe3MZVL547jno\n2BGOPTbuSEREciebyuIfmdki4BRCn0NPAANyHVg+ePZZOOYY6NIl7khERHIn2+7T1hKSwBeAk4E3\ncxZRnti8GRYuVLGQiBS+tFcEZvZJYGI0rAf+h/BEs8+0UmyxeuGFUD9w4olxRyIikluZiobeAuYD\nZ7n7UgAzu6pVosoDzz4LHTrAccfFHYmISG5lKho6D1gNPGNm95jZZwmVxUUhUT/QtWvckYiI5Fba\nRODuj7r7RcBg4Bngm8BBZvYLM/tcawUYhy1bQv2AioVEpBg0Wlns7tvc/UF3PxvoB7wK/GvOI4vR\nCy/Arl2qKBaR4rBPD110943uPtPdP5vN+mY2wczeNrOlZnZtiuW3m9lr0fCOmX2YajutTfUDIlJM\nsrmhrEnMrAS4GziV0GPpAjOb6+5vJNZx96uS1r8CGJWrePbFc8+Fzua6dYs7EhGR3MvlY9jHAkvd\nfVn0MJvZwLkZ1p8IPJTDeLKydSssWKBiIREpHrlMBH2B95OmK6N5ezGzAcBA4OkcxpMV1Q+ISLHJ\nZSLYFxcBD7v7rlQLzWyKmVWYWUVVqqfEtKDnnoP27eHTn87px4iI5I1cJoJVQP+k6X7RvFQuIkOx\nUFRBXe7u5X369GnBEPf27LOqHxCR4pLLRLAAONLMBppZR8LBfm7DlcxsMHAA8FIOY8nKtm2qHxCR\n4pOzRODuO4FphN5K3wTmuPsSM7vRzM5JWvUiYLa7e65iydaLL8LOnbqRTESKS86ajwK4+2PAYw3m\nXd9gekYuY9gXzz4LJSUwblzckYiItJ58qSzOC4n6ge7d445ERKT1KBFEEvUDKhYSkWKjRBB56SWo\nrVVFsYgUHyWCiOoHRKRYKRFE5s2D0aOhR4+4IxERaV1KBMDHH8PLL8MJJ8QdiYhI61MiIFQSf/wx\nHH983JGIiLQ+JQJCsRDA+PHxxiEiEgclAmD+fCgrg1694o5ERKT1FX0i2LUr9Dj63nvQrh2UlsKs\nWXFHJSLSenLaxURb8O//Dtu375leuRKmTAnjkybFE5OISGsq+iuC227be15NDUyf3vqxiIjEoegT\nwcaNqee/917rxiEiEpeiTgTuoV4glcMOa91YRETiUtSJ4N13Yfdu6Nix/vyuXeGmm+KJSUSktRV1\nIpg/P7z+4AcwYACYhdeZM1VRLCLFo6hbDc2fD717w3e+A9dcE3c0IiLxKPorguOPD1cCIiLFqmgT\nwQcfwLJl6l9IRKRoE0GifkCJQESKXVEngu7dYeTIuCMREYlX0SaCefPguOOgfVFXl4uIFGki2LgR\nXn9dxUIiIlCkieCFF8JdxXoimYhIkSaC+fOhQwcYOzbuSERE4le0ieDoo6FLl7gjERGJX9Elgu3b\noaJC9QMiIglFlwj+9jeorVUiEBFJKLpEMG9e6FJi3Li4IxERyQ9Flwjmz4fhw6Fnz7gjERHJD0WV\nCHbuhJdeUrGQiEiyokoEr74K27YpEYiIJCuqRKCO5kRE9lZ0iWDQIDj00LgjERHJH0WTCNz3PIhG\nRET2KJpE8OabUF2tRCAi0lDRJIJE/YA6mhMRqS+nicDMJpjZ22a21MyuTbPOP5vZG2a2xMwezFUs\ngwbBV78aXkVEZI+cPZbFzEqAu4FTgUpggZnNdfc3ktY5EvguMM7dN5rZQbmK55RTwiAiIvXl8opg\nLLDU3Ze5+w5gNnBug3W+Ctzt7hsB3H1dDuMREZEUcpkI+gLvJ01XRvOSfRL4pJm9YGZ/NbMJqTZk\nZlPMrMLMKqqqqnIUrohIcYq7srg9cCRwEjARuMfM9uoFyN1nunu5u5f36dOnlUMUESlsuUwEq4D+\nSdP9onnJKoG57l7r7suBdwiJQUREWkkuE8EC4EgzG2hmHYGLgLkN1nmUcDWAmfUmFBUty2FMIiLS\nQM4SgbvvBKYBTwBvAnPcfYmZ3Whm50SrPQFUm9kbwDPAd9y9OlcxiYjI3szd445hn5SXl3tFRUXc\nYYiItClmttDdy1Mti7uyWEREYqZEICJS5JQIRESKnBKBiEiRUyIQESlySgQiIkVOiUBEpMgpEYiI\nFDklAhGRIqdEICJS5JQIRESKnBKBiEiRUyIQESlySgQiIkVOiUBEpMgpEYiIFLmiSASzZkFpKbRr\nF15nzYo7IhGR/NE+7gBybdYsmDIFamrC9MqVYRpg0qT44hIRyRcFf0UwffqeJJBQUxPmi4hIESSC\n997bt/kiIsWm4BPBYYft23wRkWJT8Ingppuga9f687p2DfNFRKQIEsGkSTBzJgwYAGbhdeZMVRSL\niCQUfKshCAd9HfhFRFIr+CsCERHJTIlARKTIKRGIiBQ5JQIRkSKnRCAiUuTM3eOOYZ+YWRWwMs3i\n3sD6VgxnX+VzfIqtaRRb0yi2pmlObAPcvU+qBW0uEWRiZhXuXh53HOnkc3yKrWkUW9MotqbJVWwq\nGhIRKXJKBCIiRa7QEsHMuANoRD7Hp9iaRrE1jWJrmpzEVlB1BCIisu8K7YpARET2kRKBiEiRK5hE\nYGYTzOxtM1tqZtfGHU8yM1thZn83s9fMrCLmWH5lZuvM7PWkeQea2V/M7N3o9YA8im2Gma2K9t1r\nZnZGTLH1N7NnzOwNM1tiZldG82Pfdxlii33fmVlnM3vZzBZFsX0/mj/QzP4W/b/+j5l1zKPYfmNm\ny5P228jWji0pxhIze9XM/hBN52a/uXubH4AS4B/A4UBHYBFQFndcSfGtAHrHHUcUywnAaOD1pHk/\nBq6Nxq8FfpRHsc0Avp0H++1QYHQ03gN4ByjLh32XIbbY9x1gQPdovAPwN+BYYA5wUTT/P4HL8yi2\n3wAXxP03F8V1NfAg8IdoOif7rVCuCMYCS919mbvvAGYD58YcU15y93nAhgazzwXujcbvBf6pVYOK\npIktL7j7and/JRrfArwJ9CUP9l2G2GLnwdZoskM0OHAy8HA0P679li62vGBm/YAzgf+Kpo0c7bdC\nSQR9gfeTpivJk3+EiAN/NrOFZjYl7mBSONjdV0fja4CD4wwmhWlmtjgqOoql2CqZmZUCowhnkHm1\n7xrEBnmw76LijdeAdcBfCFfvH7r7zmiV2P5fG8bm7on9dlO03243s05xxAbcAVwD7I6me5Gj/VYo\niSDfjXf30cDpwNfN7IS4A0rHwzVn3pwVAb8ABgEjgdXAbXEGY2bdgd8C33T3zcnL4t53KWLLi33n\n7rvcfSTQj3D1PjiOOFJpGJuZDQW+S4jxaOBA4F9bOy4zOwtY5+4LW+PzCiURrAL6J033i+blBXdf\nFb2uAx4h/DPkk7VmdihA9Lou5njquPva6J91N3APMe47M+tAONDOcvf/i2bnxb5LFVs+7bsong+B\nZ4DjgJ5mlnhUbuz/r0mxTYiK2tzdPwZ+TTz7bRxwjpmtIBR1nwzcSY72W6EkggXAkVGNekfgImBu\nzDEBYGbdzKxHYhz4HPB65ne1urnAl6LxLwG/izGWehIH2cjniWnfReWz/w286e4/TVoU+75LF1s+\n7Dsz62NmPaPxLsCphDqMZ4ALotXi2m+pYnsrKbEboQy+1febu3/X3fu5eynhePa0u08iV/st7lrx\nlhqAMwitJf4BTI87nqS4Die0YloELIk7NuAhQjFBLaGM8SuEssengHeBJ4ED8yi2+4G/A4sJB91D\nY4ptPKHYZzHwWjSckQ/7LkNsse87YDjwahTD68D10fzDgZeBpcD/Ap3yKLano/32OvAAUcuiuAbg\nJPa0GsrJflMXEyIiRa5QioZERKSJlAhERIqcEoGISJFTIhARKXJKBCIiRU6JQCRiZruSepx8zVqw\nF1szK03uVVUkn7RvfBWRorHdQ3cDIkVFVwQijbDwPIkfW3imxMtmdkQ0v9TMno46J3vKzA6L5h9s\nZo9E/dwvMrNPR5sqMbN7or7v/xzdzYqZfSN6lsBiM5sd09eUIqZEILJHlwZFQxcmLdvk7sOAnxN6\nhQT4GXCvuw8HZgF3RfPvAp5z9xGE5yssieYfCdzt7kOAD4Hzo/nXAqOi7UzN1ZcTSUd3FotEzGyr\nu3dPMX8FcLK7L4s6d1vj7r3MbD2h24baaP5qd+9tZlVAPw+dliW2UUro5vjIaPpfgQ7u/kMz+xOw\nFXgUeNT39JEv0ip0RSCSHU8zvi8+ThrfxZ46ujOBuwlXDwuSepcUaRVKBCLZuTDp9aVo/EVCz5AA\nk4D50fhTwOVQ9+CT/dNt1MzaAf3d/RlCv/f7A3tdlYjkks48RPboEj2tKuFP7p5oQnqAmS0mnNVP\njOZdAfzazL4DVAFfjuZfCcw0s68QzvwvJ/SqmkoJ8ECULAy4y0Pf+CKtRnUEIo2I6gjK3X193LGI\n5IKKhkREipyuCEREipyuCEREipwSgYhIkVMiEBEpckoEIiJFTolARKTI/X/1l2n/AceEqgAAAABJ\nRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history2.history\n",
    "\n",
    "acc = history_dict['acc']\n",
    "val_acc = history_dict['val_acc']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7FBpTc_rXGvQ"
   },
   "source": [
    "The accuracy of model2 is 87%. Using Embedding layer instead of one-hot layer improved the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "--020hfG6rN2"
   },
   "source": [
    "### Using pre-trained word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J4gBeOyi4gkM"
   },
   "source": [
    "The Embedding layer can be used to load a pre-trained word embedding model. We are going to use GloVe embeddings, which you can read about it here (https://nlp.stanford.edu/projects/glove/). GloVe stands for \"Global Vectors for Word Representation\". It's a somewhat popular embedding technique based on factorizing a matrix of word co-occurence statistics. You can download GloVe and we can seed the Keras Embedding layer with weights from the pre-trained embedding for the words in your dataset.\n",
    "First, we need to read GloVe and map words to GloVe:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "mOsgGRXg77cq",
    "outputId": "9370b45b-11ef-4393-e374-fcb6af457de8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chakin\n",
      "  Downloading https://files.pythonhosted.org/packages/ca/3f/ca2f63451c0ab47970a6ab1d39d96118e70b6e73125529cea767c31368a3/chakin-0.0.8-py3-none-any.whl\n",
      "Requirement already satisfied: progressbar2>=3.20.0 in /usr/local/lib/python3.6/dist-packages (from chakin) (3.38.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from chakin) (1.12.0)\n",
      "Requirement already satisfied: pandas>=0.20.1 in /usr/local/lib/python3.6/dist-packages (from chakin) (0.25.3)\n",
      "Requirement already satisfied: python-utils>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from progressbar2>=3.20.0->chakin) (2.3.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.20.1->chakin) (2018.9)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.20.1->chakin) (1.17.5)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.20.1->chakin) (2.6.1)\n",
      "Installing collected packages: chakin\n",
      "Successfully installed chakin-0.0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100% ||                                      | Time:  0:06:27   2.1 MiB/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./glove.6B.zip'"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install chakin\n",
    "import chakin\n",
    "chakin.download(number=12, save_dir='./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f_PypdqG9Iis"
   },
   "outputs": [],
   "source": [
    "def readGloveFile(gloveFile):\n",
    "    with open(gloveFile, 'r') as f:\n",
    "        wordToGlove = {}  \n",
    "        wordToIndex = {}  \n",
    "        indexToWord = {}  \n",
    "\n",
    "        for line in f:\n",
    "            record = line.strip().split()\n",
    "            token = record[0] \n",
    "            wordToGlove[token] = np.array(record[1:], dtype=np.float64) \n",
    "            \n",
    "        tokens = sorted(wordToGlove.keys())\n",
    "        for idx, tok in enumerate(tokens):\n",
    "            kerasIdx = idx + 1  \n",
    "            wordToIndex[tok] = kerasIdx \n",
    "            indexToWord[kerasIdx] = tok \n",
    "\n",
    "    return wordToIndex, indexToWord, wordToGlove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZcIZ3dq59bCh"
   },
   "source": [
    "Now, we create our pre-trained Embedding layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gembn7VM3ex8"
   },
   "outputs": [],
   "source": [
    "def createPretrainedEmbeddingLayer(wordToGlove, wordToIndex, isTrainable):\n",
    "    vocabLen = len(wordToIndex) + 1  \n",
    "    embDim = next(iter(wordToGlove.values())).shape[0]  \n",
    "   \n",
    "    embeddingMatrix = np.zeros((vocabLen, embDim))  \n",
    "    for word, index in wordToIndex.items():\n",
    "        embeddingMatrix[index, :] = wordToGlove[word] \n",
    "\n",
    "    embeddingLayer = Embedding(vocabLen, embDim, embeddings_initializer=Constant(embeddingMatrix), trainable=isTrainable)\n",
    "    return embeddingLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HGxciLK4-xOr"
   },
   "source": [
    "We freeze the weights. To create the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PZCPUM0W_Drc"
   },
   "outputs": [],
   "source": [
    "# put the code here\n",
    "import os\n",
    "# os.system(\"unzip './glove.6B.zip' \")\n",
    "from tensorflow.contrib.keras.api.keras.initializers import Constant\n",
    "wordToIndex, indexToWord, wordToGlove = readGloveFile('./glove.6B.300d.txt')\n",
    "embeddingLayer = createPretrainedEmbeddingLayer(wordToGlove, wordToIndex, isTrainable=True)\n",
    "# os.system(\"rm './glove.6B.zip'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M-bZ5SCHiIMl"
   },
   "source": [
    "### Adding another hidden layer to the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZbZ6UBDfbjea"
   },
   "source": [
    "In model3, we only add another dense layer to see if that improves the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vw0le1YjDdCa"
   },
   "outputs": [],
   "source": [
    "# put your code here\n",
    "model3 = Sequential()\n",
    "# model3.add(Embedding(VOCAB_SIZE,16,input_length=MAX_SEQUENCE_LENGTH))\n",
    "model3.add(embeddingLayer)\n",
    "model3.add(GlobalAveragePooling1DMasked())\n",
    "model3.add(Dense(16,activation='relu'))\n",
    "model3.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "TgiSSc-dI_05",
    "outputId": "6d86dbd1-7a3c-4ce1-ddfc-7f64e418f5e6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:421: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 120000300 elements. This may consume a large amount of memory.\n",
      "  num_elements)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "15000/15000 [==============================] - 8s 541us/step - loss: 0.6855 - acc: 0.5761 - val_loss: 0.6744 - val_acc: 0.6283\n",
      "Epoch 2/40\n",
      "15000/15000 [==============================] - 3s 190us/step - loss: 0.6570 - acc: 0.6768 - val_loss: 0.6393 - val_acc: 0.6912\n",
      "Epoch 3/40\n",
      "15000/15000 [==============================] - 3s 191us/step - loss: 0.6083 - acc: 0.7225 - val_loss: 0.5818 - val_acc: 0.7416\n",
      "Epoch 4/40\n",
      "15000/15000 [==============================] - 3s 191us/step - loss: 0.5346 - acc: 0.7811 - val_loss: 0.5042 - val_acc: 0.8000\n",
      "Epoch 5/40\n",
      "15000/15000 [==============================] - 3s 191us/step - loss: 0.4516 - acc: 0.8307 - val_loss: 0.4328 - val_acc: 0.8351\n",
      "Epoch 6/40\n",
      "15000/15000 [==============================] - 3s 190us/step - loss: 0.3803 - acc: 0.8596 - val_loss: 0.3821 - val_acc: 0.8518\n",
      "Epoch 7/40\n",
      "15000/15000 [==============================] - 3s 191us/step - loss: 0.3276 - acc: 0.8797 - val_loss: 0.3475 - val_acc: 0.8646\n",
      "Epoch 8/40\n",
      "15000/15000 [==============================] - 3s 191us/step - loss: 0.2900 - acc: 0.8914 - val_loss: 0.3274 - val_acc: 0.8708\n",
      "Epoch 9/40\n",
      "15000/15000 [==============================] - 3s 190us/step - loss: 0.2585 - acc: 0.9060 - val_loss: 0.3109 - val_acc: 0.8749\n",
      "Epoch 10/40\n",
      "15000/15000 [==============================] - 3s 191us/step - loss: 0.2336 - acc: 0.9145 - val_loss: 0.3013 - val_acc: 0.8783\n",
      "Epoch 11/40\n",
      "15000/15000 [==============================] - 3s 189us/step - loss: 0.2128 - acc: 0.9244 - val_loss: 0.2958 - val_acc: 0.8798\n",
      "Epoch 12/40\n",
      "15000/15000 [==============================] - 3s 191us/step - loss: 0.1933 - acc: 0.9322 - val_loss: 0.2905 - val_acc: 0.8839\n",
      "Epoch 13/40\n",
      "15000/15000 [==============================] - 3s 193us/step - loss: 0.1768 - acc: 0.9399 - val_loss: 0.2892 - val_acc: 0.8856\n",
      "Epoch 14/40\n",
      "15000/15000 [==============================] - 3s 192us/step - loss: 0.1624 - acc: 0.9468 - val_loss: 0.2964 - val_acc: 0.8790\n",
      "Epoch 15/40\n",
      "15000/15000 [==============================] - 3s 192us/step - loss: 0.1505 - acc: 0.9517 - val_loss: 0.2936 - val_acc: 0.8841\n",
      "Epoch 16/40\n",
      "15000/15000 [==============================] - 3s 192us/step - loss: 0.1378 - acc: 0.9577 - val_loss: 0.2936 - val_acc: 0.8850\n",
      "Epoch 17/40\n",
      "15000/15000 [==============================] - 3s 192us/step - loss: 0.1266 - acc: 0.9624 - val_loss: 0.3019 - val_acc: 0.8823\n",
      "Epoch 18/40\n",
      "15000/15000 [==============================] - 3s 191us/step - loss: 0.1197 - acc: 0.9642 - val_loss: 0.3030 - val_acc: 0.8831\n",
      "Epoch 19/40\n",
      "15000/15000 [==============================] - 3s 191us/step - loss: 0.1080 - acc: 0.9695 - val_loss: 0.3090 - val_acc: 0.8824\n",
      "Epoch 20/40\n",
      "15000/15000 [==============================] - 3s 193us/step - loss: 0.1003 - acc: 0.9716 - val_loss: 0.3177 - val_acc: 0.8791\n",
      "Epoch 21/40\n",
      "15000/15000 [==============================] - 3s 191us/step - loss: 0.0931 - acc: 0.9754 - val_loss: 0.3210 - val_acc: 0.8812\n",
      "Epoch 22/40\n",
      "15000/15000 [==============================] - 3s 191us/step - loss: 0.0855 - acc: 0.9779 - val_loss: 0.3289 - val_acc: 0.8806\n",
      "Epoch 23/40\n",
      "15000/15000 [==============================] - 3s 191us/step - loss: 0.0794 - acc: 0.9805 - val_loss: 0.3392 - val_acc: 0.8797\n",
      "Epoch 24/40\n",
      "15000/15000 [==============================] - 3s 191us/step - loss: 0.0742 - acc: 0.9826 - val_loss: 0.3454 - val_acc: 0.8774\n",
      "Epoch 25/40\n",
      "15000/15000 [==============================] - 3s 192us/step - loss: 0.0678 - acc: 0.9849 - val_loss: 0.3580 - val_acc: 0.8774\n",
      "Epoch 26/40\n",
      "15000/15000 [==============================] - 3s 194us/step - loss: 0.0624 - acc: 0.9863 - val_loss: 0.3666 - val_acc: 0.8762\n",
      "Epoch 27/40\n",
      "15000/15000 [==============================] - 3s 194us/step - loss: 0.0571 - acc: 0.9884 - val_loss: 0.3798 - val_acc: 0.8738\n",
      "Epoch 28/40\n",
      "15000/15000 [==============================] - 3s 193us/step - loss: 0.0521 - acc: 0.9898 - val_loss: 0.3892 - val_acc: 0.8744\n",
      "Epoch 29/40\n",
      "15000/15000 [==============================] - 3s 194us/step - loss: 0.0483 - acc: 0.9913 - val_loss: 0.4015 - val_acc: 0.8729\n",
      "Epoch 30/40\n",
      "15000/15000 [==============================] - 3s 192us/step - loss: 0.0446 - acc: 0.9921 - val_loss: 0.4141 - val_acc: 0.8726\n",
      "Epoch 31/40\n",
      "15000/15000 [==============================] - 3s 192us/step - loss: 0.0411 - acc: 0.9939 - val_loss: 0.4259 - val_acc: 0.8724\n",
      "Epoch 32/40\n",
      "15000/15000 [==============================] - 3s 193us/step - loss: 0.0382 - acc: 0.9944 - val_loss: 0.4373 - val_acc: 0.8708\n",
      "Epoch 33/40\n",
      "15000/15000 [==============================] - 3s 194us/step - loss: 0.0354 - acc: 0.9947 - val_loss: 0.4496 - val_acc: 0.8702\n",
      "Epoch 34/40\n",
      "15000/15000 [==============================] - 3s 196us/step - loss: 0.0327 - acc: 0.9955 - val_loss: 0.4658 - val_acc: 0.8677\n",
      "Epoch 35/40\n",
      "15000/15000 [==============================] - 3s 193us/step - loss: 0.0302 - acc: 0.9965 - val_loss: 0.4737 - val_acc: 0.8693\n",
      "Epoch 36/40\n",
      "15000/15000 [==============================] - 3s 195us/step - loss: 0.0274 - acc: 0.9966 - val_loss: 0.4803 - val_acc: 0.8683\n",
      "Epoch 37/40\n",
      "15000/15000 [==============================] - 3s 192us/step - loss: 0.0248 - acc: 0.9971 - val_loss: 0.4934 - val_acc: 0.8681\n",
      "Epoch 38/40\n",
      "15000/15000 [==============================] - 3s 192us/step - loss: 0.0234 - acc: 0.9973 - val_loss: 0.5048 - val_acc: 0.8674\n",
      "Epoch 39/40\n",
      "15000/15000 [==============================] - 3s 194us/step - loss: 0.0217 - acc: 0.9982 - val_loss: 0.5146 - val_acc: 0.8653\n",
      "Epoch 40/40\n",
      "15000/15000 [==============================] - 3s 195us/step - loss: 0.0197 - acc: 0.9983 - val_loss: 0.5243 - val_acc: 0.8652\n",
      "25000/25000 [==============================] - 1s 42us/step\n",
      "[0.5604358990383148, 0.8528]\n"
     ]
    }
   ],
   "source": [
    "model3.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "X_val = np.array(X_train_enc[:10000])\n",
    "partial_X_train = np.array(X_train_enc[10000:])\n",
    "\n",
    "history3 = model3.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=40,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)\n",
    "\n",
    "results = model3.evaluate(X_test_enc, y_test)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 56
    },
    "colab_type": "code",
    "id": "2vSN29uCKQ_L",
    "outputId": "561d94aa-8c29-46c8-b315-92f36450beb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 1s 41us/step\n",
      "[0.5604358990383148, 0.8528]\n"
     ]
    }
   ],
   "source": [
    "results = model3.evaluate(X_test_enc, y_test)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "QtsdVeW7UgCu",
    "outputId": "b37ee091-3a01-431c-cbbe-0a8a59ebc791"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZDklAhGRLPf/AarPSju4XDpGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history3.history\n",
    "\n",
    "acc = history_dict['acc']\n",
    "val_acc = history_dict['val_acc']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kx--Ytk3ZbLo"
   },
   "source": [
    "The accuracy of model3 with an additional layer is 85%. Adding more layers can help you to extract more features. But we can do that upto a certain extent. After some point, instead of extracting features, we tend to overfit the data. Overfitting can lead to errors in some or the other form like false positives. It is not easy to choose the number of units in a hidden layer or the number of hidden layers in a neural network. For many applications, one hidden layer is enough. As a general rule, the number of units in that hidden layer is between the number of inputs and the number of outputs.\n",
    " The best way to decide on the number of units and hidden layers is to try various parameters. Train several neural networks with different numbers of hidden layers and neurons, and monitor the performance of them. You will have to experiment using a series of different architectures. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gn2GSV4ioyO2"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XYC6DykEox2w"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GsCJ01StlgCx"
   },
   "source": [
    "This tutorial is substantially based on this document:\n",
    "https://www.tensorflow.org/tutorials/keras/basic_text_classification\n",
    "\n",
    "To read more about Sequential APIs you can go to: https://keras.io/getting-started/sequential-model-guide/\n",
    "\n",
    "The one-hot word vector layer is taken from:\n",
    "https://fdalvi.github.io/blog/2018-04-07-keras-sequential-onehot/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jL0UovfaE9GE"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "lab4_text_classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
